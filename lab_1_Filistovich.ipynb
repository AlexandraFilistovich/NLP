{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>cult, horror, gothic, murder, atmospheric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>inspiring, romantic, stupid, feel-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>tt0249380</td>\n",
       "      <td>Baise-moi tells the story of Nadine and Manu w...</td>\n",
       "      <td>gothic, cruelty, violence, cult, revenge, sadist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>tt0408790</td>\n",
       "      <td>Kyle Pratt (Jodie Foster) is a propulsion engi...</td>\n",
       "      <td>mystery, suspenseful, action, murder, flashback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                      plot_synopsis  \\\n",
       "0           0  tt0057603  Note: this synopsis is for the orginal Italian...   \n",
       "1           1  tt1733125  Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2           3  tt0113862  Glenn Holland, not a morning person by anyone'...   \n",
       "3           6  tt0249380  Baise-moi tells the story of Nadine and Manu w...   \n",
       "4           7  tt0408790  Kyle Pratt (Jodie Foster) is a propulsion engi...   \n",
       "\n",
       "                                               tags  \n",
       "0         cult, horror, gothic, murder, atmospheric  \n",
       "1                                          violence  \n",
       "2            inspiring, romantic, stupid, feel-good  \n",
       "3  gothic, cruelty, violence, cult, revenge, sadist  \n",
       "4   mystery, suspenseful, action, murder, flashback  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>plot_synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>tt1315981</td>\n",
       "      <td>George Falconer (Colin Firth) approaches a car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>tt1937113</td>\n",
       "      <td>Hours after the end of the previous game and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>tt1619029</td>\n",
       "      <td>The film begins with a close-up of Jackie Kenn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                      plot_synopsis\n",
       "0           2  tt0033045  Matuschek's, a gift store in Budapest, is the ...\n",
       "1           4  tt0086250  In May 1980, a Cuban man named Tony Montana (A...\n",
       "2           5  tt1315981  George Falconer (Colin Firth) approaches a car...\n",
       "3          15  tt1937113  Hours after the end of the previous game and t...\n",
       "4          18  tt1619029  The film begins with a close-up of Jackie Kenn..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data = pd.read_csv('data_test_all.csv')\n",
    "final_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_absurd</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_adult comedy</th>\n",
       "      <th>is_allegory</th>\n",
       "      <th>is_alternate history</th>\n",
       "      <th>is_alternate reality</th>\n",
       "      <th>is_anti war</th>\n",
       "      <th>is_atmospheric</th>\n",
       "      <th>is_autobiographical</th>\n",
       "      <th>is_avant garde</th>\n",
       "      <th>...</th>\n",
       "      <th>is_sentimental</th>\n",
       "      <th>is_storytelling</th>\n",
       "      <th>is_stupid</th>\n",
       "      <th>is_suicidal</th>\n",
       "      <th>is_suspenseful</th>\n",
       "      <th>is_thought-provoking</th>\n",
       "      <th>is_tragedy</th>\n",
       "      <th>is_violence</th>\n",
       "      <th>is_western</th>\n",
       "      <th>is_whimsical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_absurd  is_action  is_adult comedy  is_allegory  is_alternate history  \\\n",
       "0          0          0                0            0                     0   \n",
       "1          0          0                0            0                     0   \n",
       "2          0          0                0            0                     0   \n",
       "3          0          0                0            0                     0   \n",
       "4          0          1                0            0                     0   \n",
       "\n",
       "   is_alternate reality  is_anti war  is_atmospheric  is_autobiographical  \\\n",
       "0                     0            0               1                    0   \n",
       "1                     0            0               0                    0   \n",
       "2                     0            0               0                    0   \n",
       "3                     0            0               0                    0   \n",
       "4                     0            0               0                    0   \n",
       "\n",
       "   is_avant garde  ...  is_sentimental  is_storytelling  is_stupid  \\\n",
       "0               0  ...               0                0          0   \n",
       "1               0  ...               0                0          0   \n",
       "2               0  ...               0                0          1   \n",
       "3               0  ...               0                0          0   \n",
       "4               0  ...               0                0          0   \n",
       "\n",
       "   is_suicidal  is_suspenseful  is_thought-provoking  is_tragedy  is_violence  \\\n",
       "0            0               0                     0           0            0   \n",
       "1            0               0                     0           0            1   \n",
       "2            0               0                     0           0            0   \n",
       "3            0               0                     0           0            1   \n",
       "4            0               1                     0           0            0   \n",
       "\n",
       "   is_western  is_whimsical  \n",
       "0           0             0  \n",
       "1           0             0  \n",
       "2           0             0  \n",
       "3           0             0  \n",
       "4           0             0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['splitted_tags'] = train_data.tags.str.split(', ')\n",
    "genres = pd.get_dummies(train_data['splitted_tags'].apply(pd.Series).stack(), prefix='is').sum(level=0)\n",
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Note: this synopsis is for the orginal Italian...</td>\n",
       "      <td>tt0057603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n",
       "      <td>tt1733125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Glenn Holland, not a morning person by anyone'...</td>\n",
       "      <td>tt0113862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baise-moi tells the story of Nadine and Manu w...</td>\n",
       "      <td>tt0249380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Kyle Pratt (Jodie Foster) is a propulsion engi...</td>\n",
       "      <td>tt0408790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \n",
       "0  Note: this synopsis is for the orginal Italian...  tt0057603  \n",
       "1  Two thousand years ago, Nhagruul the Foul, a s...  tt1733125  \n",
       "2  Glenn Holland, not a morning person by anyone'...  tt0113862  \n",
       "3  Baise-moi tells the story of Nadine and Manu w...  tt0249380  \n",
       "4  Kyle Pratt (Jodie Foster) is a propulsion engi...  tt0408790  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed = pd.DataFrame()\n",
    "train_processed['is_murder'] = genres.is_murder\n",
    "train_processed['is_romantic'] = genres.is_romantic\n",
    "train_processed['is_comedy'] = genres.is_comedy\n",
    "train_processed['is_fantasy'] = genres.is_fantasy\n",
    "train_processed['is_flashback'] = genres.is_flashback\n",
    "\n",
    "train_processed['plot_synopsis'] = train_data.plot_synopsis\n",
    "train_processed['id'] = train_data.id\n",
    "\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, this, synopsis, is, for, the, orginal, ...</td>\n",
       "      <td>tt0057603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, years, ago, nhagruul, the, fou...</td>\n",
       "      <td>tt1733125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, not, a, morning, person, by, ...</td>\n",
       "      <td>tt0113862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tells, the, story, of, nadine, and,...</td>\n",
       "      <td>tt0249380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodie, foster, is, a, propulsion...</td>\n",
       "      <td>tt0408790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \n",
       "0  [note, this, synopsis, is, for, the, orginal, ...  tt0057603  \n",
       "1  [two, thousand, years, ago, nhagruul, the, fou...  tt1733125  \n",
       "2  [glenn, holland, not, a, morning, person, by, ...  tt0113862  \n",
       "3  [baisemoi, tells, the, story, of, nadine, and,...  tt0249380  \n",
       "4  [kyle, pratt, jodie, foster, is, a, propulsion...  tt0408790  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed['plot_synopsis'] = train_processed.plot_synopsis.str.lower()\n",
    "train_processed['plot_synopsis'] = train_processed.plot_synopsis.str.translate(str.maketrans('', '', string.punctuation))\n",
    "train_processed['plot_synopsis'] = train_processed.plot_synopsis.str.split()\n",
    "\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n",
       "      <td>tt0033045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n",
       "      <td>tt0086250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Falconer (Colin Firth) approaches a car...</td>\n",
       "      <td>tt1315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hours after the end of the previous game and t...</td>\n",
       "      <td>tt1937113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The film begins with a close-up of Jackie Kenn...</td>\n",
       "      <td>tt1619029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id\n",
       "0  Matuschek's, a gift store in Budapest, is the ...  tt0033045\n",
       "1  In May 1980, a Cuban man named Tony Montana (A...  tt0086250\n",
       "2  George Falconer (Colin Firth) approaches a car...  tt1315981\n",
       "3  Hours after the end of the previous game and t...  tt1937113\n",
       "4  The film begins with a close-up of Jackie Kenn...  tt1619029"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed = pd.DataFrame()\n",
    "test_processed['plot_synopsis'] = final_test_data.plot_synopsis\n",
    "test_processed['id'] = final_test_data.id\n",
    "\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuscheks, a, gift, store, in, budapest, is,...</td>\n",
       "      <td>tt0033045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[in, may, 1980, a, cuban, man, named, tony, mo...</td>\n",
       "      <td>tt0086250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[george, falconer, colin, firth, approaches, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hours, after, the, end, of, the, previous, ga...</td>\n",
       "      <td>tt1937113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, film, begins, with, a, closeup, of, jack...</td>\n",
       "      <td>tt1619029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id\n",
       "0  [matuscheks, a, gift, store, in, budapest, is,...  tt0033045\n",
       "1  [in, may, 1980, a, cuban, man, named, tony, mo...  tt0086250\n",
       "2  [george, falconer, colin, firth, approaches, a...  tt1315981\n",
       "3  [hours, after, the, end, of, the, previous, ga...  tt1937113\n",
       "4  [the, film, begins, with, a, closeup, of, jack...  tt1619029"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['plot_synopsis'] = test_processed.plot_synopsis.str.lower()\n",
    "test_processed['plot_synopsis'] = test_processed.plot_synopsis.str.translate(str.maketrans('', '', string.punctuation))\n",
    "test_processed['plot_synopsis'] = test_processed.plot_synopsis.str.split()\n",
    "\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stops = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsis, orginal, italian, release, se...</td>\n",
       "      <td>tt0057603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, years, ago, nhagruul, foul, so...</td>\n",
       "      <td>tt1733125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morning, person, anyones, sta...</td>\n",
       "      <td>tt0113862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tells, story, nadine, manu, go, vio...</td>\n",
       "      <td>tt0249380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodie, foster, propulsion, engin...</td>\n",
       "      <td>tt0408790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \n",
       "0  [note, synopsis, orginal, italian, release, se...  tt0057603  \n",
       "1  [two, thousand, years, ago, nhagruul, foul, so...  tt1733125  \n",
       "2  [glenn, holland, morning, person, anyones, sta...  tt0113862  \n",
       "3  [baisemoi, tells, story, nadine, manu, go, vio...  tt0249380  \n",
       "4  [kyle, pratt, jodie, foster, propulsion, engin...  tt0408790  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed['plot_synopsis'] = train_processed['plot_synopsis'].apply(lambda l: [word for word in l if word not in eng_stops])\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuscheks, gift, store, budapest, workplace,...</td>\n",
       "      <td>tt0033045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, named, tony, montana, ...</td>\n",
       "      <td>tt0086250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[george, falconer, colin, firth, approaches, c...</td>\n",
       "      <td>tt1315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hours, end, previous, game, death, traitorous...</td>\n",
       "      <td>tt1937113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begins, closeup, jackie, kennedy, natal...</td>\n",
       "      <td>tt1619029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id\n",
       "0  [matuscheks, gift, store, budapest, workplace,...  tt0033045\n",
       "1  [may, 1980, cuban, man, named, tony, montana, ...  tt0086250\n",
       "2  [george, falconer, colin, firth, approaches, c...  tt1315981\n",
       "3  [hours, end, previous, game, death, traitorous...  tt1937113\n",
       "4  [film, begins, closeup, jackie, kennedy, natal...  tt1619029"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['plot_synopsis'] = test_processed['plot_synopsis'].apply(lambda l: [word for word in l if word not in eng_stops])\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.snowball.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603  \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125  \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862  \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380  \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed['plot_synopsis'] = train_processed['plot_synopsis'].apply(lambda l: [stemmer.stem(word) for word in l])\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045\n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250\n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981\n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113\n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['plot_synopsis'] = test_processed['plot_synopsis'].apply(lambda l: [stemmer.stem(word) for word in l])\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603  \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125  \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862  \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380  \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed['plot_synopsis'] = train_processed['plot_synopsis'].apply(lambda l: [lemmatizer.lemmatize(word) for word in l])\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045\n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250\n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981\n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113\n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['plot_synopsis'] = test_processed['plot_synopsis'].apply(lambda l: [lemmatizer.lemmatize(word) for word in l])\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>known beset alfonsi estrang mari frank frank p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>dismay sold surviv blood rose knight gave knig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>taken find timeconsum princip wrote helen got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "      <td>feel get manu detach act detach happen get tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "      <td>marlen design find begin seen hurt crew crew f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \\\n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603   \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125   \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862   \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380   \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790   \n",
       "\n",
       "                                               verbs  \n",
       "0  known beset alfonsi estrang mari frank frank p...  \n",
       "1  dismay sold surviv blood rose knight gave knig...  \n",
       "2  taken find timeconsum princip wrote helen got ...  \n",
       "3  feel get manu detach act detach happen get tel...  \n",
       "4  marlen design find begin seen hurt crew crew f...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verbs(l):\n",
    "    tag = ['VB', 'VBD', 'VBG', 'VBN']\n",
    "    tagged_list = pos_tag(l)\n",
    "    #print(tagged_list)\n",
    "    tagged_words = []\n",
    "    for word, pos in tagged_list:\n",
    "        if pos in tag:\n",
    "            tagged_words.append(word)\n",
    "    return ' '.join(tagged_words)\n",
    "\n",
    "\n",
    "train_processed['verbs'] = train_processed['plot_synopsis'].apply(verbs)\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>sent meet frank best lost find chosen hed hurt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>left steven kill kill hit set crew met set ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "      <td>snowwhit kiss ring told feel tell given given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "      <td>forc fled safetymeanwhil led william take figh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "      <td>begin told arriv impress broadcasterw go done ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id  \\\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045   \n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250   \n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981   \n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113   \n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029   \n",
       "\n",
       "                                               verbs  \n",
       "0  sent meet frank best lost find chosen hed hurt...  \n",
       "1  left steven kill kill hit set crew met set ang...  \n",
       "2  snowwhit kiss ring told feel tell given given ...  \n",
       "3  forc fled safetymeanwhil led william take figh...  \n",
       "4  begin told arriv impress broadcasterw go done ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['verbs'] = test_processed['plot_synopsis'].apply(verbs)\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>known beset alfonsi estrang mari frank frank p...</td>\n",
       "      <td>note synopsi orgin releas segment karloff intr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>dismay sold surviv blood rose knight gave knig...</td>\n",
       "      <td>year foul sorcer revel innoc spread despair da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>taken find timeconsum princip wrote helen got ...</td>\n",
       "      <td>glenn person standard wife iri septemb morn gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "      <td>feel get manu detach act detach happen get tel...</td>\n",
       "      <td>baisemoi tell nadin manu spree societi margin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "      <td>marlen design find begin seen hurt crew crew f...</td>\n",
       "      <td>pratt jodi foster base berlin germani husband ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \\\n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603   \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125   \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862   \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380   \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  known beset alfonsi estrang mari frank frank p...   \n",
       "1  dismay sold surviv blood rose knight gave knig...   \n",
       "2  taken find timeconsum princip wrote helen got ...   \n",
       "3  feel get manu detach act detach happen get tel...   \n",
       "4  marlen design find begin seen hurt crew crew f...   \n",
       "\n",
       "                                               nouns  \n",
       "0  note synopsi orgin releas segment karloff intr...  \n",
       "1  year foul sorcer revel innoc spread despair da...  \n",
       "2  glenn person standard wife iri septemb morn gl...  \n",
       "3  baisemoi tell nadin manu spree societi margin ...  \n",
       "4  pratt jodi foster base berlin germani husband ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nouns(l):\n",
    "    tag = ['NN', 'NNP', 'NNS']\n",
    "    tagged_list = pos_tag(l)\n",
    "    #print(tagged_list)\n",
    "    tagged_words = []\n",
    "    for word, pos in tagged_list:\n",
    "        if pos in tag:\n",
    "            tagged_words.append(word)\n",
    "    return ' '.join(tagged_words)\n",
    "\n",
    "\n",
    "train_processed['nouns'] = train_processed['plot_synopsis'].apply(nouns)\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>sent meet frank best lost find chosen hed hurt...</td>\n",
       "      <td>matuschek gift store workplac alfr kralik jame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>left steven kill kill hit set crew met set ang...</td>\n",
       "      <td>cuban man name montana al pacino claim asylum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "      <td>snowwhit kiss ring told feel tell given given ...</td>\n",
       "      <td>falcon colin firth approach car accid middl bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "      <td>forc fled safetymeanwhil led william take figh...</td>\n",
       "      <td>hour end game death traitor shepard remnant ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "      <td>begin told arriv impress broadcasterw go done ...</td>\n",
       "      <td>film closeup jacki kennedi natali portman port...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id  \\\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045   \n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250   \n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981   \n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113   \n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  sent meet frank best lost find chosen hed hurt...   \n",
       "1  left steven kill kill hit set crew met set ang...   \n",
       "2  snowwhit kiss ring told feel tell given given ...   \n",
       "3  forc fled safetymeanwhil led william take figh...   \n",
       "4  begin told arriv impress broadcasterw go done ...   \n",
       "\n",
       "                                               nouns  \n",
       "0  matuschek gift store workplac alfr kralik jame...  \n",
       "1  cuban man name montana al pacino claim asylum ...  \n",
       "2  falcon colin firth approach car accid middl bl...  \n",
       "3  hour end game death traitor shepard remnant ta...  \n",
       "4  film closeup jacki kennedi natali portman port...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['nouns'] = test_processed['plot_synopsis'].apply(nouns)\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>known beset alfonsi estrang mari frank frank p...</td>\n",
       "      <td>note synopsi orgin releas segment karloff intr...</td>\n",
       "      <td>italian certain orderbori telephonerosi attrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>dismay sold surviv blood rose knight gave knig...</td>\n",
       "      <td>year foul sorcer revel innoc spread despair da...</td>\n",
       "      <td>nhagruul end mortal consum excruci ritual beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>taken find timeconsum princip wrote helen got ...</td>\n",
       "      <td>glenn person standard wife iri septemb morn gl...</td>\n",
       "      <td>morn anyon bright newli high musician free fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "      <td>feel get manu detach act detach happen get tel...</td>\n",
       "      <td>baisemoi tell nadin manu spree societi margin ...</td>\n",
       "      <td>violent parttim small southern friend troubl g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "      <td>marlen design find begin seen hurt crew crew f...</td>\n",
       "      <td>pratt jodi foster base berlin germani husband ...</td>\n",
       "      <td>kyle engin build yearold lawston buri kyle kyl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \\\n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603   \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125   \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862   \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380   \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  known beset alfonsi estrang mari frank frank p...   \n",
       "1  dismay sold surviv blood rose knight gave knig...   \n",
       "2  taken find timeconsum princip wrote helen got ...   \n",
       "3  feel get manu detach act detach happen get tel...   \n",
       "4  marlen design find begin seen hurt crew crew f...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  note synopsi orgin releas segment karloff intr...   \n",
       "1  year foul sorcer revel innoc spread despair da...   \n",
       "2  glenn person standard wife iri septemb morn gl...   \n",
       "3  baisemoi tell nadin manu spree societi margin ...   \n",
       "4  pratt jodi foster base berlin germani husband ...   \n",
       "\n",
       "                                          adjectives  \n",
       "0  italian certain orderbori telephonerosi attrac...  \n",
       "1  nhagruul end mortal consum excruci ritual beca...  \n",
       "2  morn anyon bright newli high musician free fir...  \n",
       "3  violent parttim small southern friend troubl g...  \n",
       "4  kyle engin build yearold lawston buri kyle kyl...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjectives(l):\n",
    "    tag = ['JJ', 'JJR', 'JJS']\n",
    "    tagged_list = pos_tag(l)\n",
    "    #print(tagged_list)\n",
    "    tagged_words = []\n",
    "    for word, pos in tagged_list:\n",
    "        if pos in tag:\n",
    "            tagged_words.append(word)\n",
    "    return ' '.join(tagged_words)\n",
    "\n",
    "\n",
    "train_processed['adjectives'] = train_processed['plot_synopsis'].apply(adjectives)\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>sent meet frank best lost find chosen hed hurt...</td>\n",
       "      <td>matuschek gift store workplac alfr kralik jame...</td>\n",
       "      <td>budapest stewart novak margaret constant secre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>left steven kill kill hit set crew met set ang...</td>\n",
       "      <td>cuban man name montana al pacino claim asylum ...</td>\n",
       "      <td>toni usa american offici notic arm black ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "      <td>snowwhit kiss ring told feel tell given given ...</td>\n",
       "      <td>falcon colin firth approach car accid middl bl...</td>\n",
       "      <td>georg sceneri wake good fate fatal homophobia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "      <td>forc fled safetymeanwhil led william take figh...</td>\n",
       "      <td>hour end game death traitor shepard remnant ta...</td>\n",
       "      <td>previous general john mactavish afghanistan sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "      <td>begin told arriv impress broadcasterw go done ...</td>\n",
       "      <td>film closeup jacki kennedi natali portman port...</td>\n",
       "      <td>hyanni novemb temporarili live sorri realli ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id  \\\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045   \n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250   \n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981   \n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113   \n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  sent meet frank best lost find chosen hed hurt...   \n",
       "1  left steven kill kill hit set crew met set ang...   \n",
       "2  snowwhit kiss ring told feel tell given given ...   \n",
       "3  forc fled safetymeanwhil led william take figh...   \n",
       "4  begin told arriv impress broadcasterw go done ...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  matuschek gift store workplac alfr kralik jame...   \n",
       "1  cuban man name montana al pacino claim asylum ...   \n",
       "2  falcon colin firth approach car accid middl bl...   \n",
       "3  hour end game death traitor shepard remnant ta...   \n",
       "4  film closeup jacki kennedi natali portman port...   \n",
       "\n",
       "                                          adjectives  \n",
       "0  budapest stewart novak margaret constant secre...  \n",
       "1  toni usa american offici notic arm black ident...  \n",
       "2  georg sceneri wake good fate fatal homophobia ...  \n",
       "3  previous general john mactavish afghanistan sa...  \n",
       "4  hyanni novemb temporarili live sorri realli ho...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['adjectives'] = test_processed['plot_synopsis'].apply(adjectives)\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>numeral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>known beset alfonsi estrang mari frank frank p...</td>\n",
       "      <td>note synopsi orgin releas segment karloff intr...</td>\n",
       "      <td>italian certain orderbori telephonerosi attrac...</td>\n",
       "      <td>three three two one one one two 19th one one f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>dismay sold surviv blood rose knight gave knig...</td>\n",
       "      <td>year foul sorcer revel innoc spread despair da...</td>\n",
       "      <td>nhagruul end mortal consum excruci ritual beca...</td>\n",
       "      <td>two thousand hundr three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>taken find timeconsum princip wrote helen got ...</td>\n",
       "      <td>glenn person standard wife iri septemb morn gl...</td>\n",
       "      <td>morn anyon bright newli high musician free fir...</td>\n",
       "      <td>one 1964 four one 1965 one 60 70 three one 197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "      <td>feel get manu detach act detach happen get tel...</td>\n",
       "      <td>baisemoi tell nadin manu spree societi margin ...</td>\n",
       "      <td>violent parttim small southern friend troubl g...</td>\n",
       "      <td>one three two one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "      <td>marlen design find begin seen hurt crew crew f...</td>\n",
       "      <td>pratt jodi foster base berlin germani husband ...</td>\n",
       "      <td>kyle engin build yearold lawston buri kyle kyl...</td>\n",
       "      <td>six 474 one one two one 50000000 one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \\\n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603   \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125   \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862   \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380   \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  known beset alfonsi estrang mari frank frank p...   \n",
       "1  dismay sold surviv blood rose knight gave knig...   \n",
       "2  taken find timeconsum princip wrote helen got ...   \n",
       "3  feel get manu detach act detach happen get tel...   \n",
       "4  marlen design find begin seen hurt crew crew f...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  note synopsi orgin releas segment karloff intr...   \n",
       "1  year foul sorcer revel innoc spread despair da...   \n",
       "2  glenn person standard wife iri septemb morn gl...   \n",
       "3  baisemoi tell nadin manu spree societi margin ...   \n",
       "4  pratt jodi foster base berlin germani husband ...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0  italian certain orderbori telephonerosi attrac...   \n",
       "1  nhagruul end mortal consum excruci ritual beca...   \n",
       "2  morn anyon bright newli high musician free fir...   \n",
       "3  violent parttim small southern friend troubl g...   \n",
       "4  kyle engin build yearold lawston buri kyle kyl...   \n",
       "\n",
       "                                             numeral  \n",
       "0  three three two one one one two 19th one one f...  \n",
       "1                           two thousand hundr three  \n",
       "2  one 1964 four one 1965 one 60 70 three one 197...  \n",
       "3                                  one three two one  \n",
       "4               six 474 one one two one 50000000 one  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numeral(l):\n",
    "    tag = ['CD']\n",
    "    tagged_list = pos_tag(l)\n",
    "    #print(tagged_list)\n",
    "    tagged_words = []\n",
    "    for word, pos in tagged_list:\n",
    "        if pos in tag:\n",
    "            tagged_words.append(word)\n",
    "    return ' '.join(tagged_words)\n",
    "\n",
    "\n",
    "train_processed['numeral'] = train_processed['plot_synopsis'].apply(numeral)\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>numeral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>sent meet frank best lost find chosen hed hurt...</td>\n",
       "      <td>matuschek gift store workplac alfr kralik jame...</td>\n",
       "      <td>budapest stewart novak margaret constant secre...</td>\n",
       "      <td>one 1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>left steven kill kill hit set crew met set ang...</td>\n",
       "      <td>cuban man name montana al pacino claim asylum ...</td>\n",
       "      <td>toni usa american offici notic arm black ident...</td>\n",
       "      <td>1980 1980 three 30 500 1000 two 25000 5000 two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "      <td>snowwhit kiss ring told feel tell given given ...</td>\n",
       "      <td>falcon colin firth approach car accid middl bl...</td>\n",
       "      <td>georg sceneri wake good fate fatal homophobia ...</td>\n",
       "      <td>16 30 1962 one one 1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "      <td>forc fled safetymeanwhil led william take figh...</td>\n",
       "      <td>hour end game death traitor shepard remnant ta...</td>\n",
       "      <td>previous general john mactavish afghanistan sa...</td>\n",
       "      <td>141 one two one 911 one thousand zone zakhaev ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "      <td>begin told arriv impress broadcasterw go done ...</td>\n",
       "      <td>film closeup jacki kennedi natali portman port...</td>\n",
       "      <td>hyanni novemb temporarili live sorri realli ho...</td>\n",
       "      <td>1963 one 1962 56 million 60 one one one three ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id  \\\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045   \n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250   \n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981   \n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113   \n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  sent meet frank best lost find chosen hed hurt...   \n",
       "1  left steven kill kill hit set crew met set ang...   \n",
       "2  snowwhit kiss ring told feel tell given given ...   \n",
       "3  forc fled safetymeanwhil led william take figh...   \n",
       "4  begin told arriv impress broadcasterw go done ...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  matuschek gift store workplac alfr kralik jame...   \n",
       "1  cuban man name montana al pacino claim asylum ...   \n",
       "2  falcon colin firth approach car accid middl bl...   \n",
       "3  hour end game death traitor shepard remnant ta...   \n",
       "4  film closeup jacki kennedi natali portman port...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0  budapest stewart novak margaret constant secre...   \n",
       "1  toni usa american offici notic arm black ident...   \n",
       "2  georg sceneri wake good fate fatal homophobia ...   \n",
       "3  previous general john mactavish afghanistan sa...   \n",
       "4  hyanni novemb temporarili live sorri realli ho...   \n",
       "\n",
       "                                             numeral  \n",
       "0                                           one 1928  \n",
       "1  1980 1980 three 30 500 1000 two 25000 5000 two...  \n",
       "2                            16 30 1962 one one 1946  \n",
       "3  141 one two one 911 one thousand zone zakhaev ...  \n",
       "4  1963 one 1962 56 million 60 one one one three ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['numeral'] = test_processed['plot_synopsis'].apply(numeral)\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>numeral</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[note, synopsi, orgin, italian, releas, segmen...</td>\n",
       "      <td>tt0057603</td>\n",
       "      <td>known beset alfonsi estrang mari frank frank p...</td>\n",
       "      <td>note synopsi orgin releas segment karloff intr...</td>\n",
       "      <td>italian certain orderbori telephonerosi attrac...</td>\n",
       "      <td>three three two one one one two 19th one one f...</td>\n",
       "      <td>note synopsi orgin italian releas segment cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[two, thousand, year, ago, nhagruul, foul, sor...</td>\n",
       "      <td>tt1733125</td>\n",
       "      <td>dismay sold surviv blood rose knight gave knig...</td>\n",
       "      <td>year foul sorcer revel innoc spread despair da...</td>\n",
       "      <td>nhagruul end mortal consum excruci ritual beca...</td>\n",
       "      <td>two thousand hundr three</td>\n",
       "      <td>two thousand year ago nhagruul foul sorcer rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[glenn, holland, morn, person, anyon, standard...</td>\n",
       "      <td>tt0113862</td>\n",
       "      <td>taken find timeconsum princip wrote helen got ...</td>\n",
       "      <td>glenn person standard wife iri septemb morn gl...</td>\n",
       "      <td>morn anyon bright newli high musician free fir...</td>\n",
       "      <td>one 1964 four one 1965 one 60 70 three one 197...</td>\n",
       "      <td>glenn holland morn person anyon standard woken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[baisemoi, tell, stori, nadin, manu, go, viole...</td>\n",
       "      <td>tt0249380</td>\n",
       "      <td>feel get manu detach act detach happen get tel...</td>\n",
       "      <td>baisemoi tell nadin manu spree societi margin ...</td>\n",
       "      <td>violent parttim small southern friend troubl g...</td>\n",
       "      <td>one three two one</td>\n",
       "      <td>baisemoi tell stori nadin manu go violent spre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[kyle, pratt, jodi, foster, propuls, engin, ba...</td>\n",
       "      <td>tt0408790</td>\n",
       "      <td>marlen design find begin seen hurt crew crew f...</td>\n",
       "      <td>pratt jodi foster base berlin germani husband ...</td>\n",
       "      <td>kyle engin build yearold lawston buri kyle kyl...</td>\n",
       "      <td>six 474 one one two one 50000000 one</td>\n",
       "      <td>kyle pratt jodi foster propuls engin base berl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback  \\\n",
       "0          1            0          0           0             0   \n",
       "1          0            0          0           0             0   \n",
       "2          0            1          0           0             0   \n",
       "3          0            0          0           0             0   \n",
       "4          1            0          0           0             1   \n",
       "\n",
       "                                       plot_synopsis         id  \\\n",
       "0  [note, synopsi, orgin, italian, releas, segmen...  tt0057603   \n",
       "1  [two, thousand, year, ago, nhagruul, foul, sor...  tt1733125   \n",
       "2  [glenn, holland, morn, person, anyon, standard...  tt0113862   \n",
       "3  [baisemoi, tell, stori, nadin, manu, go, viole...  tt0249380   \n",
       "4  [kyle, pratt, jodi, foster, propuls, engin, ba...  tt0408790   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  known beset alfonsi estrang mari frank frank p...   \n",
       "1  dismay sold surviv blood rose knight gave knig...   \n",
       "2  taken find timeconsum princip wrote helen got ...   \n",
       "3  feel get manu detach act detach happen get tel...   \n",
       "4  marlen design find begin seen hurt crew crew f...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  note synopsi orgin releas segment karloff intr...   \n",
       "1  year foul sorcer revel innoc spread despair da...   \n",
       "2  glenn person standard wife iri septemb morn gl...   \n",
       "3  baisemoi tell nadin manu spree societi margin ...   \n",
       "4  pratt jodi foster base berlin germani husband ...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0  italian certain orderbori telephonerosi attrac...   \n",
       "1  nhagruul end mortal consum excruci ritual beca...   \n",
       "2  morn anyon bright newli high musician free fir...   \n",
       "3  violent parttim small southern friend troubl g...   \n",
       "4  kyle engin build yearold lawston buri kyle kyl...   \n",
       "\n",
       "                                             numeral  \\\n",
       "0  three three two one one one two 19th one one f...   \n",
       "1                           two thousand hundr three   \n",
       "2  one 1964 four one 1965 one 60 70 three one 197...   \n",
       "3                                  one three two one   \n",
       "4               six 474 one one two one 50000000 one   \n",
       "\n",
       "                                                plot  \n",
       "0  note synopsi orgin italian releas segment cert...  \n",
       "1  two thousand year ago nhagruul foul sorcer rev...  \n",
       "2  glenn holland morn person anyon standard woken...  \n",
       "3  baisemoi tell stori nadin manu go violent spre...  \n",
       "4  kyle pratt jodi foster propuls engin base berl...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed['plot'] = train_processed['plot_synopsis'].apply(lambda l: ' '.join(l))\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>id</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>numeral</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[matuschek, gift, store, budapest, workplac, a...</td>\n",
       "      <td>tt0033045</td>\n",
       "      <td>sent meet frank best lost find chosen hed hurt...</td>\n",
       "      <td>matuschek gift store workplac alfr kralik jame...</td>\n",
       "      <td>budapest stewart novak margaret constant secre...</td>\n",
       "      <td>one 1928</td>\n",
       "      <td>matuschek gift store budapest workplac alfr kr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[may, 1980, cuban, man, name, toni, montana, a...</td>\n",
       "      <td>tt0086250</td>\n",
       "      <td>left steven kill kill hit set crew met set ang...</td>\n",
       "      <td>cuban man name montana al pacino claim asylum ...</td>\n",
       "      <td>toni usa american offici notic arm black ident...</td>\n",
       "      <td>1980 1980 three 30 500 1000 two 25000 5000 two...</td>\n",
       "      <td>may 1980 cuban man name toni montana al pacino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[georg, falcon, colin, firth, approach, car, a...</td>\n",
       "      <td>tt1315981</td>\n",
       "      <td>snowwhit kiss ring told feel tell given given ...</td>\n",
       "      <td>falcon colin firth approach car accid middl bl...</td>\n",
       "      <td>georg sceneri wake good fate fatal homophobia ...</td>\n",
       "      <td>16 30 1962 one one 1946</td>\n",
       "      <td>georg falcon colin firth approach car accid mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hour, end, previous, game, death, traitor, ge...</td>\n",
       "      <td>tt1937113</td>\n",
       "      <td>forc fled safetymeanwhil led william take figh...</td>\n",
       "      <td>hour end game death traitor shepard remnant ta...</td>\n",
       "      <td>previous general john mactavish afghanistan sa...</td>\n",
       "      <td>141 one two one 911 one thousand zone zakhaev ...</td>\n",
       "      <td>hour end previous game death traitor general s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[film, begin, closeup, jacki, kennedi, natali,...</td>\n",
       "      <td>tt1619029</td>\n",
       "      <td>begin told arriv impress broadcasterw go done ...</td>\n",
       "      <td>film closeup jacki kennedi natali portman port...</td>\n",
       "      <td>hyanni novemb temporarili live sorri realli ho...</td>\n",
       "      <td>1963 one 1962 56 million 60 one one one three ...</td>\n",
       "      <td>film begin closeup jacki kennedi natali portma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       plot_synopsis         id  \\\n",
       "0  [matuschek, gift, store, budapest, workplac, a...  tt0033045   \n",
       "1  [may, 1980, cuban, man, name, toni, montana, a...  tt0086250   \n",
       "2  [georg, falcon, colin, firth, approach, car, a...  tt1315981   \n",
       "3  [hour, end, previous, game, death, traitor, ge...  tt1937113   \n",
       "4  [film, begin, closeup, jacki, kennedi, natali,...  tt1619029   \n",
       "\n",
       "                                               verbs  \\\n",
       "0  sent meet frank best lost find chosen hed hurt...   \n",
       "1  left steven kill kill hit set crew met set ang...   \n",
       "2  snowwhit kiss ring told feel tell given given ...   \n",
       "3  forc fled safetymeanwhil led william take figh...   \n",
       "4  begin told arriv impress broadcasterw go done ...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  matuschek gift store workplac alfr kralik jame...   \n",
       "1  cuban man name montana al pacino claim asylum ...   \n",
       "2  falcon colin firth approach car accid middl bl...   \n",
       "3  hour end game death traitor shepard remnant ta...   \n",
       "4  film closeup jacki kennedi natali portman port...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0  budapest stewart novak margaret constant secre...   \n",
       "1  toni usa american offici notic arm black ident...   \n",
       "2  georg sceneri wake good fate fatal homophobia ...   \n",
       "3  previous general john mactavish afghanistan sa...   \n",
       "4  hyanni novemb temporarili live sorri realli ho...   \n",
       "\n",
       "                                             numeral  \\\n",
       "0                                           one 1928   \n",
       "1  1980 1980 three 30 500 1000 two 25000 5000 two...   \n",
       "2                            16 30 1962 one one 1946   \n",
       "3  141 one two one 911 one thousand zone zakhaev ...   \n",
       "4  1963 one 1962 56 million 60 one one one three ...   \n",
       "\n",
       "                                                plot  \n",
       "0  matuschek gift store budapest workplac alfr kr...  \n",
       "1  may 1980 cuban man name toni montana al pacino...  \n",
       "2  georg falcon colin firth approach car accid mi...  \n",
       "3  hour end previous game death traitor general s...  \n",
       "4  film begin closeup jacki kennedi natali portma...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed['plot'] = test_processed['plot_synopsis'].apply(lambda l: ' '.join(l))\n",
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(s):\n",
    "    t = RegexpTokenizer(r'\\w+')\n",
    "    return t.tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>numeral</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>known beset alfonsi estrang mari frank frank p...</td>\n",
       "      <td>note synopsi orgin releas segment karloff intr...</td>\n",
       "      <td>italian certain orderbori telephonerosi attrac...</td>\n",
       "      <td>three three two one one one two 19th one one f...</td>\n",
       "      <td>note synopsi orgin italian releas segment cert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dismay sold surviv blood rose knight gave knig...</td>\n",
       "      <td>year foul sorcer revel innoc spread despair da...</td>\n",
       "      <td>nhagruul end mortal consum excruci ritual beca...</td>\n",
       "      <td>two thousand hundr three</td>\n",
       "      <td>two thousand year ago nhagruul foul sorcer rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taken find timeconsum princip wrote helen got ...</td>\n",
       "      <td>glenn person standard wife iri septemb morn gl...</td>\n",
       "      <td>morn anyon bright newli high musician free fir...</td>\n",
       "      <td>one 1964 four one 1965 one 60 70 three one 197...</td>\n",
       "      <td>glenn holland morn person anyon standard woken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel get manu detach act detach happen get tel...</td>\n",
       "      <td>baisemoi tell nadin manu spree societi margin ...</td>\n",
       "      <td>violent parttim small southern friend troubl g...</td>\n",
       "      <td>one three two one</td>\n",
       "      <td>baisemoi tell stori nadin manu go violent spre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marlen design find begin seen hurt crew crew f...</td>\n",
       "      <td>pratt jodi foster base berlin germani husband ...</td>\n",
       "      <td>kyle engin build yearold lawston buri kyle kyl...</td>\n",
       "      <td>six 474 one one two one 50000000 one</td>\n",
       "      <td>kyle pratt jodi foster propuls engin base berl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               verbs  \\\n",
       "0  known beset alfonsi estrang mari frank frank p...   \n",
       "1  dismay sold surviv blood rose knight gave knig...   \n",
       "2  taken find timeconsum princip wrote helen got ...   \n",
       "3  feel get manu detach act detach happen get tel...   \n",
       "4  marlen design find begin seen hurt crew crew f...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  note synopsi orgin releas segment karloff intr...   \n",
       "1  year foul sorcer revel innoc spread despair da...   \n",
       "2  glenn person standard wife iri septemb morn gl...   \n",
       "3  baisemoi tell nadin manu spree societi margin ...   \n",
       "4  pratt jodi foster base berlin germani husband ...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0  italian certain orderbori telephonerosi attrac...   \n",
       "1  nhagruul end mortal consum excruci ritual beca...   \n",
       "2  morn anyon bright newli high musician free fir...   \n",
       "3  violent parttim small southern friend troubl g...   \n",
       "4  kyle engin build yearold lawston buri kyle kyl...   \n",
       "\n",
       "                                             numeral  \\\n",
       "0  three three two one one one two 19th one one f...   \n",
       "1                           two thousand hundr three   \n",
       "2  one 1964 four one 1965 one 60 70 three one 197...   \n",
       "3                                  one three two one   \n",
       "4               six 474 one one two one 50000000 one   \n",
       "\n",
       "                                                plot  \n",
       "0  note synopsi orgin italian releas segment cert...  \n",
       "1  two thousand year ago nhagruul foul sorcer rev...  \n",
       "2  glenn holland morn person anyon standard woken...  \n",
       "3  baisemoi tell stori nadin manu go violent spre...  \n",
       "4  kyle pratt jodi foster propuls engin base berl...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat = train_processed.copy()\n",
    "train_feat = train_feat.drop(['is_murder','is_romantic','is_comedy','is_fantasy', 'is_flashback', 'id', 'plot_synopsis'],axis=1)\n",
    "\n",
    "train_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_murder</th>\n",
       "      <th>is_romantic</th>\n",
       "      <th>is_comedy</th>\n",
       "      <th>is_fantasy</th>\n",
       "      <th>is_flashback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_murder  is_romantic  is_comedy  is_fantasy  is_flashback\n",
       "0          1            0          0           0             0\n",
       "1          0            0          0           0             0\n",
       "2          0            1          0           0             0\n",
       "3          0            0          0           0             0\n",
       "4          1            0          0           0             1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val = train_processed.copy()\n",
    "train_val = train_val.drop(['plot_synopsis', 'id', 'verbs', 'nouns', 'adjectives', 'numeral', 'plot'],axis=1)\n",
    "train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tt0057603\n",
       "1    tt1733125\n",
       "2    tt0113862\n",
       "3    tt0249380\n",
       "4    tt0408790\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id = train_processed['id']\n",
    "train_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>adjectives</th>\n",
       "      <th>numeral</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sent meet frank best lost find chosen hed hurt...</td>\n",
       "      <td>matuschek gift store workplac alfr kralik jame...</td>\n",
       "      <td>budapest stewart novak margaret constant secre...</td>\n",
       "      <td>one 1928</td>\n",
       "      <td>matuschek gift store budapest workplac alfr kr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left steven kill kill hit set crew met set ang...</td>\n",
       "      <td>cuban man name montana al pacino claim asylum ...</td>\n",
       "      <td>toni usa american offici notic arm black ident...</td>\n",
       "      <td>1980 1980 three 30 500 1000 two 25000 5000 two...</td>\n",
       "      <td>may 1980 cuban man name toni montana al pacino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snowwhit kiss ring told feel tell given given ...</td>\n",
       "      <td>falcon colin firth approach car accid middl bl...</td>\n",
       "      <td>georg sceneri wake good fate fatal homophobia ...</td>\n",
       "      <td>16 30 1962 one one 1946</td>\n",
       "      <td>georg falcon colin firth approach car accid mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forc fled safetymeanwhil led william take figh...</td>\n",
       "      <td>hour end game death traitor shepard remnant ta...</td>\n",
       "      <td>previous general john mactavish afghanistan sa...</td>\n",
       "      <td>141 one two one 911 one thousand zone zakhaev ...</td>\n",
       "      <td>hour end previous game death traitor general s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>begin told arriv impress broadcasterw go done ...</td>\n",
       "      <td>film closeup jacki kennedi natali portman port...</td>\n",
       "      <td>hyanni novemb temporarili live sorri realli ho...</td>\n",
       "      <td>1963 one 1962 56 million 60 one one one three ...</td>\n",
       "      <td>film begin closeup jacki kennedi natali portma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               verbs  \\\n",
       "0  sent meet frank best lost find chosen hed hurt...   \n",
       "1  left steven kill kill hit set crew met set ang...   \n",
       "2  snowwhit kiss ring told feel tell given given ...   \n",
       "3  forc fled safetymeanwhil led william take figh...   \n",
       "4  begin told arriv impress broadcasterw go done ...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  matuschek gift store workplac alfr kralik jame...   \n",
       "1  cuban man name montana al pacino claim asylum ...   \n",
       "2  falcon colin firth approach car accid middl bl...   \n",
       "3  hour end game death traitor shepard remnant ta...   \n",
       "4  film closeup jacki kennedi natali portman port...   \n",
       "\n",
       "                                          adjectives  \\\n",
       "0  budapest stewart novak margaret constant secre...   \n",
       "1  toni usa american offici notic arm black ident...   \n",
       "2  georg sceneri wake good fate fatal homophobia ...   \n",
       "3  previous general john mactavish afghanistan sa...   \n",
       "4  hyanni novemb temporarili live sorri realli ho...   \n",
       "\n",
       "                                             numeral  \\\n",
       "0                                           one 1928   \n",
       "1  1980 1980 three 30 500 1000 two 25000 5000 two...   \n",
       "2                            16 30 1962 one one 1946   \n",
       "3  141 one two one 911 one thousand zone zakhaev ...   \n",
       "4  1963 one 1962 56 million 60 one one one three ...   \n",
       "\n",
       "                                                plot  \n",
       "0  matuschek gift store budapest workplac alfr kr...  \n",
       "1  may 1980 cuban man name toni montana al pacino...  \n",
       "2  georg falcon colin firth approach car accid mi...  \n",
       "3  hour end previous game death traitor general s...  \n",
       "4  film begin closeup jacki kennedi natali portma...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat = test_processed.copy()\n",
    "test_feat = test_feat.drop(['id', 'plot_synopsis'],axis=1)\n",
    "test_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tt0033045\n",
       "1    tt0086250\n",
       "2    tt1315981\n",
       "3    tt1937113\n",
       "4    tt1619029\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = test_processed['id']\n",
    "test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ntrain_feat - all train features\\ntrain_val - all train genres (validation)\\ntrain_id - train id\\n\\nX_train - 0.7 train features\\nX_test - 0.3 train features for estimation \\ny_train - 0.7 train valid\\ny_test - 0.3 train valid for estimation\\n\\ntest_feat - final test features\\ntest_id - final test ids\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "train_feat - all train features\n",
    "train_val - all train genres (validation)\n",
    "train_id - train id\n",
    "\n",
    "X_train - 0.7 train features\n",
    "X_test - 0.3 train features for estimation \n",
    "y_train - 0.7 train valid\n",
    "y_test - 0.3 train valid for estimation\n",
    "\n",
    "test_feat - final test features\n",
    "test_id - final test ids\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_y, y_test_y = train_test_split(train_feat, train_val, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(\n",
    "    max_features=20000,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "cv_ngram_binary = CountVectorizer(\n",
    "    ngram_range=[1, 2],\n",
    "    max_features=40000,\n",
    "    tokenizer=tokenizer,\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=30000\n",
    ")\n",
    "\n",
    "tfidf_maxdf = TfidfVectorizer(\n",
    "    max_df=0.8,\n",
    "    max_features=10000\n",
    ")\n",
    "\n",
    "\n",
    "tfidf_bigr = TfidfVectorizer(\n",
    "    max_df=0.8,\n",
    "    max_features=30000,\n",
    "    tokenizer=tokenizer,\n",
    "    ngram_range=[1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vector = {}\n",
    "X_test_vector = {}\n",
    "X_train_all_global = {}\n",
    "X_test_all_vector = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot for cv vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\valerii\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot for cv_ngram_binary vectorizer\n",
      "plot for tfidf vectorizer\n",
      "plot for tfidf_maxdf vectorizer\n",
      "plot for tfidf_bigr vectorizer\n",
      "verbs for cv vectorizer\n",
      "verbs for cv_ngram_binary vectorizer\n",
      "verbs for tfidf vectorizer\n",
      "verbs for tfidf_maxdf vectorizer\n",
      "verbs for tfidf_bigr vectorizer\n",
      "nouns for cv vectorizer\n",
      "nouns for cv_ngram_binary vectorizer\n",
      "nouns for tfidf vectorizer\n",
      "nouns for tfidf_maxdf vectorizer\n",
      "nouns for tfidf_bigr vectorizer\n",
      "adjectives for cv vectorizer\n",
      "adjectives for cv_ngram_binary vectorizer\n",
      "adjectives for tfidf vectorizer\n",
      "adjectives for tfidf_maxdf vectorizer\n",
      "adjectives for tfidf_bigr vectorizer\n",
      "numeral for cv vectorizer\n",
      "numeral for cv_ngram_binary vectorizer\n",
      "numeral for tfidf vectorizer\n",
      "numeral for tfidf_maxdf vectorizer\n",
      "numeral for tfidf_bigr vectorizer\n"
     ]
    }
   ],
   "source": [
    "for feature in ['plot', 'verbs', 'nouns', 'adjectives', 'numeral']:\n",
    "    \n",
    "    print(feature + ' for cv vectorizer')\n",
    "    cv.fit(X_train[feature])\n",
    "    X_train_vector[f'cv_{feature}'] = cv.transform(X_train[feature])\n",
    "    X_test_vector[f'cv_{feature}'] = cv.transform(X_test[feature])\n",
    "    X_train_all_global[f'cv_{feature}'] = cv.transform(train_feat[feature])\n",
    "    X_test_all_vector[f'cv_{feature}'] = cv.transform(test_feat[feature])\n",
    "    \n",
    "    print(feature + ' for cv_ngram_binary vectorizer')\n",
    "    cv_ngram_binary.fit(X_train[feature])\n",
    "    X_train_vector[f'cv_ngram_binary_{feature}'] = cv_ngram_binary.transform(X_train[feature])\n",
    "    X_test_vector[f'cv_ngram_binary_{feature}'] = cv_ngram_binary.transform(X_test[feature])\n",
    "    X_train_all_global[f'cv_ngram_binary_{feature}'] = cv_ngram_binary.transform(train_feat[feature])\n",
    "    X_test_all_vector[f'cv_ngram_binary_{feature}'] = cv_ngram_binary.transform(test_feat[feature])\n",
    "\n",
    "    print(feature + ' for tfidf vectorizer')\n",
    "    tfidf.fit(X_train[feature])\n",
    "    X_train_vector[f'tfidf_{feature}'] = tfidf.transform(X_train[feature])\n",
    "    X_test_vector[f'tfidf_{feature}'] = tfidf.transform(X_test[feature])\n",
    "    X_train_all_global[f'tfidf_{feature}'] = tfidf.transform(train_feat[feature])\n",
    "    X_test_all_vector[f'tfidf_{feature}'] = tfidf.transform(test_feat[feature])\n",
    "    \n",
    "    print(feature + ' for tfidf_maxdf vectorizer')\n",
    "    tfidf_maxdf.fit(X_train[feature])\n",
    "    X_train_vector[f'tfidf_maxdf_{feature}'] = tfidf_maxdf.transform(X_train[feature])\n",
    "    X_test_vector[f'tfidf_maxdf_{feature}'] = tfidf_maxdf.transform(X_test[feature])\n",
    "    X_train_all_global[f'tfidf_maxdf_{feature}'] = tfidf_maxdf.transform(train_feat[feature])\n",
    "    X_test_all_vector[f'tfidf_maxdf_{feature}'] = tfidf_maxdf.transform(test_feat[feature])\n",
    "    \n",
    "    print(feature + ' for tfidf_bigr vectorizer')\n",
    "    tfidf_bigr.fit(X_train[feature])\n",
    "    X_train_vector[f'tfidf_bigr_{feature}'] = tfidf_bigr.transform(X_train[feature])\n",
    "    X_test_vector[f'tfidf_bigr_{feature}'] = tfidf_bigr.transform(X_test[feature])\n",
    "    X_train_all_global[f'tfidf_bigr_{feature}'] = tfidf_bigr.transform(train_feat[feature])\n",
    "    X_test_all_vector[f'tfidf_bigr_{feature}'] = tfidf_bigr.transform(test_feat[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nX_train_vector = {}\\nX_test_vector = {}\\nX_train_all_global = {}\\nX_test_all_vector = {}\\n\\ntrain_feat - all train features\\ntrain_val - all train genres (validation)\\ntrain_id - train id\\n\\nX_train - 0.7 train features\\nX_test - 0.3 train features for estimation \\ny_train - 0.7 train valid\\ny_test - 0.3 train valid for estimation\\n\\ntest_feat - final test features\\ntest_id - final test ids\\n\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_for_genre(genre, vector, feature, classifier):\n",
    "    y_train = y_train_y[genre].values  # check train\n",
    "    y_val = y_test_y[genre].values  # check result\n",
    "    y_train_all = train_val[genre].values  # all train\n",
    "    \n",
    "    X_tr = X_train_vector[f'{vector}_{feature}']  # check train\n",
    "    X_v = X_test_vector[f'{vector}_{feature}']  # check result\n",
    "    X_train_all = X_train_all_global[f'{vector}_{feature}']  # all train\n",
    "    X_test_all = X_test_all_vector[f'{vector}_{feature}']  # ansver\n",
    "    \n",
    "    clf.fit(X_tr, y_train)\n",
    "    y_val_pred = clf.predict(X_v)\n",
    "    \n",
    "    clf.fit(X_train_all, y_train_all)\n",
    "    y_test_pred = clf.predict(X_test_all)  # ans\n",
    "    \n",
    "    return y_train, y_val, y_val_pred, y_test_pred\n",
    "\n",
    "'''\n",
    "\n",
    "X_train_vector = {}\n",
    "X_test_vector = {}\n",
    "X_train_all_global = {}\n",
    "X_test_all_vector = {}\n",
    "\n",
    "train_feat - all train features\n",
    "train_val - all train genres (validation)\n",
    "train_id - train id\n",
    "\n",
    "X_train - 0.7 train features\n",
    "X_test - 0.3 train features for estimation \n",
    "y_train - 0.7 train valid\n",
    "y_test - 0.3 train valid for estimation\n",
    "\n",
    "test_feat - final test features\n",
    "test_id - final test ids\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_settings(genres, vector_stra, feature_stra, classifier):\n",
    "    output = {}\n",
    "    \n",
    "    for genre in genres:\n",
    "        for vect_strategy in vect_strategies:\n",
    "            for feature in feature_strategies:\n",
    "                print(f'{genre} TRAIN FOR {vect_strategy} and {feature}')\n",
    "\n",
    "                y_train, y_val, y_val_pred, y_test_pred = fit_for_genre(genre, vect_strategy, feature, clf)\n",
    "\n",
    "                print('Test: ', f1_score(y_val, y_val_pred))\n",
    "                print('Test: ', confusion_matrix(y_val, y_val_pred))\n",
    "                print('===========================================')\n",
    "                \n",
    "                output[genre+'_'+vect_strategy+'_'+feature+'_'+str(type(clf))] = {\n",
    "                    'y_train': y_train,\n",
    "                    'y_val': y_val,\n",
    "                    'y_val_pred': y_val_pred,\n",
    "                    'y_test_all_pred': y_test_pred,\n",
    "                    'f1_test': f1_score(y_val, y_val_pred),\n",
    "                    'cm_test': confusion_matrix(y_val, y_val_pred),\n",
    "                    'clf': deepcopy(clf),\n",
    "                    'key': genre+'_'+vect_strategy+'_'+feature+'_'+str(type(clf))\n",
    "                }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['is_murder', 'is_romantic', 'is_comedy', 'is_fantasy', 'is_flashback']\n",
    "vect_strategies = ['cv_ngram_binary', 'cv', 'tfidf', 'tfidf_maxdf', 'tfidf_bigr']\n",
    "feature_strategies = ['plot', 'verbs', 'nouns', 'adjectives', 'numeral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_murder TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.5903508771929825\n",
      "Test:  [[1240  470]\n",
      " [ 464  673]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.44658119658119655\n",
      "Test:  [[1393  317]\n",
      " [ 719  418]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.5716886663632226\n",
      "Test:  [[1278  432]\n",
      " [ 509  628]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.4911749873928391\n",
      "Test:  [[1351  359]\n",
      " [ 650  487]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.24657534246575344\n",
      "Test:  [[1503  207]\n",
      " [ 948  189]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and plot\n",
      "Test:  0.5919642857142857\n",
      "Test:  [[1270  440]\n",
      " [ 474  663]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and verbs\n",
      "Test:  0.5084581923634606\n",
      "Test:  [[1304  406]\n",
      " [ 611  526]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and nouns\n",
      "Test:  0.5851254480286738\n",
      "Test:  [[1268  442]\n",
      " [ 484  653]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and adjectives\n",
      "Test:  0.493621197252208\n",
      "Test:  [[1312  398]\n",
      " [ 634  503]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and numeral\n",
      "Test:  0.251621271076524\n",
      "Test:  [[1499  211]\n",
      " [ 943  194]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and plot\n",
      "Test:  0.5865470852017938\n",
      "Test:  [[1271  439]\n",
      " [ 483  654]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and verbs\n",
      "Test:  0.5081339712918661\n",
      "Test:  [[1288  422]\n",
      " [ 606  531]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and nouns\n",
      "Test:  0.5779534475186648\n",
      "Test:  [[1228  482]\n",
      " [ 479  658]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and adjectives\n",
      "Test:  0.49586776859504134\n",
      "Test:  [[1300  410]\n",
      " [ 627  510]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and numeral\n",
      "Test:  0.2865853658536585\n",
      "Test:  [[1442  268]\n",
      " [ 902  235]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.5802016498625114\n",
      "Test:  [[1298  412]\n",
      " [ 504  633]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.47743229689067207\n",
      "Test:  [[1329  381]\n",
      " [ 661  476]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.5555555555555557\n",
      "Test:  [[1235  475]\n",
      " [ 517  620]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.49233627496516486\n",
      "Test:  [[1224  486]\n",
      " [ 607  530]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.2865853658536585\n",
      "Test:  [[1442  268]\n",
      " [ 902  235]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.6113342257920571\n",
      "Test:  [[1291  419]\n",
      " [ 452  685]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.48196392785571146\n",
      "Test:  [[1332  378]\n",
      " [ 656  481]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.578853046594982\n",
      "Test:  [[1261  449]\n",
      " [ 491  646]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.49715370018975336\n",
      "Test:  [[1263  447]\n",
      " [ 613  524]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.2984165651644336\n",
      "Test:  [[1450  260]\n",
      " [ 892  245]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.2937365010799136\n",
      "Test:  [[2057  245]\n",
      " [ 409  136]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.18134034165571616\n",
      "Test:  [[2155  147]\n",
      " [ 476   69]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.2992299229922993\n",
      "Test:  [[2074  228]\n",
      " [ 409  136]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.18686868686868688\n",
      "Test:  [[2129  173]\n",
      " [ 471   74]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.06796116504854369\n",
      "Test:  [[2250   52]\n",
      " [ 524   21]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and plot\n",
      "Test:  0.3086816720257235\n",
      "Test:  [[2058  244]\n",
      " [ 401  144]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and verbs\n",
      "Test:  0.22934648581997538\n",
      "Test:  [[2129  173]\n",
      " [ 452   93]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and nouns\n",
      "Test:  0.29487179487179493\n",
      "Test:  [[2049  253]\n",
      " [ 407  138]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and adjectives\n",
      "Test:  0.20413122721749696\n",
      "Test:  [[2108  194]\n",
      " [ 461   84]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and numeral\n",
      "Test:  0.06645569620253165\n",
      "Test:  [[2236   66]\n",
      " [ 524   21]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and plot\n",
      "Test:  0.3188976377952756\n",
      "Test:  [[1993  309]\n",
      " [ 383  162]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and verbs\n",
      "Test:  0.2415349887133183\n",
      "Test:  [[2068  234]\n",
      " [ 438  107]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and nouns\n",
      "Test:  0.29258098223615464\n",
      "Test:  [[2030  272]\n",
      " [ 405  140]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and adjectives\n",
      "Test:  0.20601851851851852\n",
      "Test:  [[2072  230]\n",
      " [ 456   89]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and numeral\n",
      "Test:  0.08895705521472393\n",
      "Test:  [[2224   78]\n",
      " [ 516   29]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.3143683702989392\n",
      "Test:  [[1973  329]\n",
      " [ 382  163]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.24507658643326038\n",
      "Test:  [[2045  257]\n",
      " [ 433  112]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.3176691729323308\n",
      "Test:  [[1952  350]\n",
      " [ 376  169]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.24471635150166857\n",
      "Test:  [[2058  244]\n",
      " [ 435  110]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.08895705521472393\n",
      "Test:  [[2224   78]\n",
      " [ 516   29]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.3374880153403644\n",
      "Test:  [[1980  322]\n",
      " [ 369  176]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.2408500590318772\n",
      "Test:  [[2102  200]\n",
      " [ 443  102]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.31958762886597936\n",
      "Test:  [[2032  270]\n",
      " [ 390  155]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.19226260257913247\n",
      "Test:  [[2076  226]\n",
      " [ 463   82]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.07976366322008864\n",
      "Test:  [[2197  105]\n",
      " [ 518   27]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.14736842105263157\n",
      "Test:  [[2319  159]\n",
      " [ 327   42]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.07048458149779735\n",
      "Test:  [[2409   69]\n",
      " [ 353   16]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.13945578231292516\n",
      "Test:  [[2300  178]\n",
      " [ 328   41]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.12108559498956158\n",
      "Test:  [[2397   81]\n",
      " [ 340   29]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.10091743119266056\n",
      "Test:  [[2433   45]\n",
      " [ 347   22]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and plot\n",
      "Test:  0.17594254937163376\n",
      "Test:  [[2339  139]\n",
      " [ 320   49]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and verbs\n",
      "Test:  0.09426229508196722\n",
      "Test:  [[2382   96]\n",
      " [ 346   23]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and nouns\n",
      "Test:  0.14705882352941177\n",
      "Test:  [[2343  135]\n",
      " [ 329   40]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and adjectives\n",
      "Test:  0.11623246492985971\n",
      "Test:  [[2377  101]\n",
      " [ 340   29]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and numeral\n",
      "Test:  0.05092592592592592\n",
      "Test:  [[2426   52]\n",
      " [ 358   11]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and plot\n",
      "Test:  0.11940298507462689\n",
      "Test:  [[2280  198]\n",
      " [ 333   36]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and verbs\n",
      "Test:  0.09696969696969697\n",
      "Test:  [[2376  102]\n",
      " [ 345   24]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and nouns\n",
      "Test:  0.18524332810047095\n",
      "Test:  [[2269  209]\n",
      " [ 310   59]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.152027027027027\n",
      "Test:  [[2300  178]\n",
      " [ 324   45]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and numeral\n",
      "Test:  0.04424778761061947\n",
      "Test:  [[2405   73]\n",
      " [ 359   10]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.16901408450704225\n",
      "Test:  [[2262  216]\n",
      " [ 315   54]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.07495069033530573\n",
      "Test:  [[2359  119]\n",
      " [ 350   19]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.15136876006441224\n",
      "Test:  [[2273  205]\n",
      " [ 322   47]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.1317157712305026\n",
      "Test:  [[2308  170]\n",
      " [ 331   38]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.04424778761061947\n",
      "Test:  [[2405   73]\n",
      " [ 359   10]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.16377952755905512\n",
      "Test:  [[2264  214]\n",
      " [ 317   52]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.056224899598393566\n",
      "Test:  [[2363  115]\n",
      " [ 355   14]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.14402618657937807\n",
      "Test:  [[2280  198]\n",
      " [ 325   44]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.12676056338028172\n",
      "Test:  [[2315  163]\n",
      " [ 333   36]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.06837606837606838\n",
      "Test:  [[2395   83]\n",
      " [ 353   16]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.4716981132075472\n",
      "Test:  [[2685   39]\n",
      " [  73   50]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.24539877300613497\n",
      "Test:  [[2704   20]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.4083769633507853\n",
      "Test:  [[2695   29]\n",
      " [  84   39]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.43434343434343436\n",
      "Test:  [[2692   32]\n",
      " [  80   43]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.08888888888888888\n",
      "Test:  [[2718    6]\n",
      " [ 117    6]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and plot\n",
      "Test:  0.46009389671361506\n",
      "Test:  [[2683   41]\n",
      " [  74   49]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and verbs\n",
      "Test:  0.22784810126582278\n",
      "Test:  [[2707   17]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and nouns\n",
      "Test:  0.4245283018867924\n",
      "Test:  [[2680   44]\n",
      " [  78   45]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and adjectives\n",
      "Test:  0.3979057591623037\n",
      "Test:  [[2694   30]\n",
      " [  85   38]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and numeral\n",
      "Test:  0.08391608391608392\n",
      "Test:  [[2710   14]\n",
      " [ 117    6]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and plot\n",
      "Test:  0.45283018867924524\n",
      "Test:  [[2683   41]\n",
      " [  75   48]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and verbs\n",
      "Test:  0.20253164556962028\n",
      "Test:  [[2705   19]\n",
      " [ 107   16]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and nouns\n",
      "Test:  0.4263959390862944\n",
      "Test:  [[2692   32]\n",
      " [  81   42]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.42424242424242425\n",
      "Test:  [[2691   33]\n",
      " [  81   42]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and numeral\n",
      "Test:  0.10256410256410257\n",
      "Test:  [[2699   25]\n",
      " [ 115    8]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.3873873873873874\n",
      "Test:  [[2668   56]\n",
      " [  80   43]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.2085889570552147\n",
      "Test:  [[2701   23]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.3823529411764706\n",
      "Test:  [[2682   42]\n",
      " [  84   39]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.4083769633507853\n",
      "Test:  [[2695   29]\n",
      " [  84   39]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.10256410256410257\n",
      "Test:  [[2699   25]\n",
      " [ 115    8]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.40178571428571425\n",
      "Test:  [[2668   56]\n",
      " [  78   45]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.2808988764044944\n",
      "Test:  [[2694   30]\n",
      " [  98   25]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.3495145631067961\n",
      "Test:  [[2677   47]\n",
      " [  87   36]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.3917525773195876\n",
      "Test:  [[2691   33]\n",
      " [  85   38]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.22222222222222224\n",
      "Test:  [[2711   13]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.3042596348884381\n",
      "Test:  [[2011  246]\n",
      " [ 440  150]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.13195342820181113\n",
      "Test:  [[2125  132]\n",
      " [ 539   51]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.26914660831509846\n",
      "Test:  [[2056  201]\n",
      " [ 467  123]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.19764705882352943\n",
      "Test:  [[2081  176]\n",
      " [ 506   84]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.08522727272727272\n",
      "Test:  [[2173   84]\n",
      " [ 560   30]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and plot\n",
      "Test:  0.30723488602576815\n",
      "Test:  [[1993  264]\n",
      " [ 435  155]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and verbs\n",
      "Test:  0.18364779874213838\n",
      "Test:  [[2125  132]\n",
      " [ 517   73]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and nouns\n",
      "Test:  0.31205673758865243\n",
      "Test:  [[2014  243]\n",
      " [ 436  154]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and adjectives\n",
      "Test:  0.2250287026406429\n",
      "Test:  [[2074  183]\n",
      " [ 492   98]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and numeral\n",
      "Test:  0.15947712418300655\n",
      "Test:  [[2143  114]\n",
      " [ 529   61]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and plot\n",
      "Test:  0.30226244343891406\n",
      "Test:  [[1909  348]\n",
      " [ 423  167]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and verbs\n",
      "Test:  0.18700114025085518\n",
      "Test:  [[2052  205]\n",
      " [ 508   82]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and nouns\n",
      "Test:  0.29701060752169717\n",
      "Test:  [[1964  293]\n",
      " [ 436  154]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and adjectives\n",
      "Test:  0.21458333333333335\n",
      "Test:  [[1990  267]\n",
      " [ 487  103]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and numeral\n",
      "Test:  0.14814814814814817\n",
      "Test:  [[2097  160]\n",
      " [ 530   60]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.2946428571428571\n",
      "Test:  [[1892  365]\n",
      " [ 425  165]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.1917808219178082\n",
      "Test:  [[2055  202]\n",
      " [ 506   84]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.2846227316141356\n",
      "Test:  [[1949  308]\n",
      " [ 441  149]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.24255319148936175\n",
      "Test:  [[2021  236]\n",
      " [ 476  114]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.14814814814814817\n",
      "Test:  [[2097  160]\n",
      " [ 530   60]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.2862523540489642\n",
      "Test:  [[1937  320]\n",
      " [ 438  152]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.18778280542986425\n",
      "Test:  [[2046  211]\n",
      " [ 507   83]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.2958459979736575\n",
      "Test:  [[2006  251]\n",
      " [ 444  146]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.2126745435016112\n",
      "Test:  [[2015  242]\n",
      " [ 491   99]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.1078167115902965\n",
      "Test:  [[2145  112]\n",
      " [ 550   40]]\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth = 39, random_state=1)\n",
    "output_dec_trees = train_with_settings(genres, vect_strategies, feature_strategies, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_murder TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.6597582037996547\n",
      "Test:  [[1295  415]\n",
      " [ 373  764]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.4967837704106878\n",
      "Test:  [[1328  382]\n",
      " [ 635  502]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.6507177033492823\n",
      "Test:  [[1296  414]\n",
      " [ 389  748]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.5765091249415067\n",
      "Test:  [[1326  384]\n",
      " [ 521  616]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.18931710615280595\n",
      "Test:  [[1508  202]\n",
      " [ 997  140]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and plot\n",
      "Test:  0.6357446808510638\n",
      "Test:  [[1244  466]\n",
      " [ 390  747]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and verbs\n",
      "Test:  0.502906976744186\n",
      "Test:  [[1302  408]\n",
      " [ 618  519]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and nouns\n",
      "Test:  0.6309523809523809\n",
      "Test:  [[1237  473]\n",
      " [ 395  742]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and adjectives\n",
      "Test:  0.5885439440314824\n",
      "Test:  [[1233  477]\n",
      " [ 464  673]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and numeral\n",
      "Test:  0.21914191419141915\n",
      "Test:  [[1498  212]\n",
      " [ 971  166]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and plot\n",
      "Test:  0.07673060884070058\n",
      "Test:  [[1694   16]\n",
      " [1091   46]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and verbs\n",
      "Test:  0.08738664468260511\n",
      "Test:  [[1687   23]\n",
      " [1084   53]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and nouns\n",
      "Test:  0.08623548922056384\n",
      "Test:  [[1693   17]\n",
      " [1085   52]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and adjectives\n",
      "Test:  0.03735144312393887\n",
      "Test:  [[1691   19]\n",
      " [1115   22]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and numeral\n",
      "Test:  0.07205764611689351\n",
      "Test:  [[1643   67]\n",
      " [1092   45]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.3750819672131147\n",
      "Test:  [[1608  102]\n",
      " [ 851  286]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.12639999999999998\n",
      "Test:  [[1676   34]\n",
      " [1058   79]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.3469524447421299\n",
      "Test:  [[1613   97]\n",
      " [ 878  259]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.23871906841339155\n",
      "Test:  [[1637   73]\n",
      " [ 973  164]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.07205764611689351\n",
      "Test:  [[1643   67]\n",
      " [1092   45]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.15445232466509062\n",
      "Test:  [[1676   34]\n",
      " [1039   98]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.11057692307692307\n",
      "Test:  [[1668   42]\n",
      " [1068   69]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.14432989690721648\n",
      "Test:  [[1677   33]\n",
      " [1046   91]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.08203445447087777\n",
      "Test:  [[1678   32]\n",
      " [1087   50]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.04304635761589404\n",
      "Test:  [[1665   45]\n",
      " [1111   26]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.46972176759410805\n",
      "Test:  [[1912  390]\n",
      " [ 258  287]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.1001669449081803\n",
      "Test:  [[2278   24]\n",
      " [ 515   30]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.42568807339449544\n",
      "Test:  [[1989  313]\n",
      " [ 313  232]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.15686274509803924\n",
      "Test:  [[2236   66]\n",
      " [ 493   52]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.03496503496503497\n",
      "Test:  [[2285   17]\n",
      " [ 535   10]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and plot\n",
      "Test:  0.42298483639265766\n",
      "Test:  [[1859  443]\n",
      " [ 280  265]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and verbs\n",
      "Test:  0.1977077363896848\n",
      "Test:  [[2218   84]\n",
      " [ 476   69]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and nouns\n",
      "Test:  0.4108910891089109\n",
      "Test:  [[1884  418]\n",
      " [ 296  249]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and adjectives\n",
      "Test:  0.33576642335766427\n",
      "Test:  [[2049  253]\n",
      " [ 384  161]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and numeral\n",
      "Test:  0.04074702886247878\n",
      "Test:  [[2270   32]\n",
      " [ 533   12]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and plot\n",
      "Test:  0.0036630036630036634\n",
      "Test:  [[2302    0]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2302    0]\n",
      " [ 545    0]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2302    0]\n",
      " [ 545    0]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and adjectives\n",
      "Test:  0.0036630036630036634\n",
      "Test:  [[2302    0]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and numeral\n",
      "Test:  0.007285974499089253\n",
      "Test:  [[2300    2]\n",
      " [ 543    2]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.0216998191681736\n",
      "Test:  [[2300    2]\n",
      " [ 539    6]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2302    0]\n",
      " [ 545    0]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.025270758122743684\n",
      "Test:  [[2300    2]\n",
      " [ 538    7]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.0036630036630036634\n",
      "Test:  [[2302    0]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.007285974499089253\n",
      "Test:  [[2300    2]\n",
      " [ 543    2]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.0036630036630036634\n",
      "Test:  [[2302    0]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.010948905109489052\n",
      "Test:  [[2302    0]\n",
      " [ 542    3]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.0036630036630036634\n",
      "Test:  [[2302    0]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.0036630036630036634\n",
      "Test:  [[2302    0]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.0036563071297989035\n",
      "Test:  [[2301    1]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.2874806800618238\n",
      "Test:  [[2293  185]\n",
      " [ 276   93]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2472    6]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.192090395480226\n",
      "Test:  [[2367  111]\n",
      " [ 318   51]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.005208333333333334\n",
      "Test:  [[2464   14]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2470    8]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and plot\n",
      "Test:  0.24436536180308424\n",
      "Test:  [[2107  371]\n",
      " [ 266  103]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and verbs\n",
      "Test:  0.0340632603406326\n",
      "Test:  [[2443   35]\n",
      " [ 362    7]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and nouns\n",
      "Test:  0.24721878862793573\n",
      "Test:  [[2138  340]\n",
      " [ 269  100]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and adjectives\n",
      "Test:  0.15520282186948856\n",
      "Test:  [[2324  154]\n",
      " [ 325   44]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and numeral\n",
      "Test:  0.0199501246882793\n",
      "Test:  [[2450   28]\n",
      " [ 365    4]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.5027322404371585\n",
      "Test:  [[2710   14]\n",
      " [  77   46]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.37735849056603776\n",
      "Test:  [[2718    6]\n",
      " [  93   30]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.24489795918367344\n",
      "Test:  [[2718    6]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and plot\n",
      "Test:  0.5303030303030303\n",
      "Test:  [[2653   71]\n",
      " [  53   70]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and verbs\n",
      "Test:  0.07407407407407408\n",
      "Test:  [[2717    7]\n",
      " [ 118    5]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and nouns\n",
      "Test:  0.5185185185185186\n",
      "Test:  [[2667   57]\n",
      " [  60   63]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and adjectives\n",
      "Test:  0.4656084656084656\n",
      "Test:  [[2702   22]\n",
      " [  79   44]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2719    5]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2724    0]\n",
      " [ 123    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.27746947835738067\n",
      "Test:  [[2071  186]\n",
      " [ 465  125]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.0226904376012966\n",
      "Test:  [[2237   20]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.24105011933174225\n",
      "Test:  [[2110  147]\n",
      " [ 489  101]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.05304212168486739\n",
      "Test:  [[2223   34]\n",
      " [ 573   17]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.019292604501607715\n",
      "Test:  [[2231   26]\n",
      " [ 584    6]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and plot\n",
      "Test:  0.3028229255774166\n",
      "Test:  [[1855  402]\n",
      " [ 413  177]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and verbs\n",
      "Test:  0.08345323741007195\n",
      "Test:  [[2181   76]\n",
      " [ 561   29]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and nouns\n",
      "Test:  0.2854609929078014\n",
      "Test:  [[1880  377]\n",
      " [ 429  161]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and adjectives\n",
      "Test:  0.218522372528616\n",
      "Test:  [[1991  266]\n",
      " [ 485  105]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and numeral\n",
      "Test:  0.03630862329803328\n",
      "Test:  [[2198   59]\n",
      " [ 578   12]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and numeral\n",
      "Test:  0.010084033613445377\n",
      "Test:  [[2255    2]\n",
      " [ 587    3]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2256    1]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.010084033613445377\n",
      "Test:  [[2255    2]\n",
      " [ 587    3]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2256    1]\n",
      " [ 590    0]]\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "output_mnb = train_with_settings(genres, vect_strategies, feature_strategies, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_murder TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.20067340067340064\n",
      "Test:  [[1511  199]\n",
      " [ 988  149]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.05382674516400337\n",
      "Test:  [[1690   20]\n",
      " [1105   32]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.11018867924528301\n",
      "Test:  [[1595  115]\n",
      " [1064   73]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.49605411499436314\n",
      "Test:  [[846 864]\n",
      " [477 660]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.3317925012840267\n",
      "Test:  [[1223  487]\n",
      " [ 814  323]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and plot\n",
      "Test:  0.4667492771581991\n",
      "Test:  [[991 719]\n",
      " [572 565]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and verbs\n",
      "Test:  0.417448923246825\n",
      "Test:  [[1414  296]\n",
      " [ 759  378]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and nouns\n",
      "Test:  0.3402777777777778\n",
      "Test:  [[1413  297]\n",
      " [ 843  294]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and adjectives\n",
      "Test:  0.4584864070536371\n",
      "Test:  [[749 961]\n",
      " [513 624]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and numeral\n",
      "Test:  0.2825059101654846\n",
      "Test:  [[1394  316]\n",
      " [ 898  239]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and plot\n",
      "Test:  0.4006147540983607\n",
      "Test:  [[1286  424]\n",
      " [ 746  391]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and verbs\n",
      "Test:  0.29666254635352285\n",
      "Test:  [[1469  241]\n",
      " [ 897  240]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and nouns\n",
      "Test:  0.3997944501541624\n",
      "Test:  [[1290  420]\n",
      " [ 748  389]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and adjectives\n",
      "Test:  0.4154447702834799\n",
      "Test:  [[1226  484]\n",
      " [ 712  425]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and numeral\n",
      "Test:  0.28212791392707715\n",
      "Test:  [[1410  300]\n",
      " [ 901  236]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.39546858908341914\n",
      "Test:  [[1289  421]\n",
      " [ 753  384]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.3022825416409624\n",
      "Test:  [[1471  239]\n",
      " [ 892  245]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.4167931208902377\n",
      "Test:  [[1282  428]\n",
      " [ 725  412]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.4149092692496321\n",
      "Test:  [[1231  479]\n",
      " [ 714  423]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.28212791392707715\n",
      "Test:  [[1410  300]\n",
      " [ 901  236]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.3939865215137377\n",
      "Test:  [[1298  412]\n",
      " [ 757  380]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.16827997021593447\n",
      "Test:  [[1617   93]\n",
      " [1024  113]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.3924374041900868\n",
      "Test:  [[1274  436]\n",
      " [ 753  384]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.4115022310361924\n",
      "Test:  [[1245  465]\n",
      " [ 722  415]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.25263157894736843\n",
      "Test:  [[1436  274]\n",
      " [ 933  204]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.021390374331550804\n",
      "Test:  [[2292   10]\n",
      " [ 539    6]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.06112054329371817\n",
      "Test:  [[2276   26]\n",
      " [ 527   18]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.0904836193447738\n",
      "Test:  [[2235   67]\n",
      " [ 516   29]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.007285974499089253\n",
      "Test:  [[2300    2]\n",
      " [ 543    2]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.06125574272588055\n",
      "Test:  [[2214   88]\n",
      " [ 525   20]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and plot\n",
      "Test:  0.08496732026143791\n",
      "Test:  [[2261   41]\n",
      " [ 519   26]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and verbs\n",
      "Test:  0.07680000000000001\n",
      "Test:  [[2246   56]\n",
      " [ 521   24]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and nouns\n",
      "Test:  0.052202283849918436\n",
      "Test:  [[2250   52]\n",
      " [ 529   16]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and adjectives\n",
      "Test:  0.02385008517887564\n",
      "Test:  [[2267   35]\n",
      " [ 538    7]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and numeral\n",
      "Test:  0.036605657237936774\n",
      "Test:  [[2257   45]\n",
      " [ 534   11]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and plot\n",
      "Test:  0.09351432880844646\n",
      "Test:  [[2215   87]\n",
      " [ 514   31]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and verbs\n",
      "Test:  0.11858974358974358\n",
      "Test:  [[2260   42]\n",
      " [ 508   37]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and nouns\n",
      "Test:  0.09667673716012086\n",
      "Test:  [[2217   85]\n",
      " [ 513   32]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and adjectives\n",
      "Test:  0.1308980213089802\n",
      "Test:  [[2233   69]\n",
      " [ 502   43]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and numeral\n",
      "Test:  0.04705882352941177\n",
      "Test:  [[2266   36]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.12391930835734871\n",
      "Test:  [[2196  106]\n",
      " [ 502   43]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.09584664536741215\n",
      "Test:  [[2251   51]\n",
      " [ 515   30]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.11386861313868614\n",
      "Test:  [[2201  101]\n",
      " [ 506   39]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.1377245508982036\n",
      "Test:  [[2225   77]\n",
      " [ 499   46]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.04705882352941177\n",
      "Test:  [[2266   36]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.1099554234769688\n",
      "Test:  [[2211   91]\n",
      " [ 508   37]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.0036429872495446266\n",
      "Test:  [[2299    3]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.10149253731343284\n",
      "Test:  [[2211   91]\n",
      " [ 511   34]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.14222222222222222\n",
      "Test:  [[2220   82]\n",
      " [ 497   48]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.026315789473684213\n",
      "Test:  [[2247   55]\n",
      " [ 537    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2478    0]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.0309278350515464\n",
      "Test:  [[2465   13]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and plot\n",
      "Test:  0.0160427807486631\n",
      "Test:  [[2476    2]\n",
      " [ 366    3]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and verbs\n",
      "Test:  0.03645833333333333\n",
      "Test:  [[2470    8]\n",
      " [ 362    7]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2474    4]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and adjectives\n",
      "Test:  0.0160427807486631\n",
      "Test:  [[2476    2]\n",
      " [ 366    3]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and numeral\n",
      "Test:  0.03608247422680412\n",
      "Test:  [[2466   12]\n",
      " [ 362    7]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and plot\n",
      "Test:  0.030075187969924814\n",
      "Test:  [[2454   24]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and verbs\n",
      "Test:  0.04316546762589929\n",
      "Test:  [[2439   39]\n",
      " [ 360    9]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and nouns\n",
      "Test:  0.05025125628140704\n",
      "Test:  [[2459   19]\n",
      " [ 359   10]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.04878048780487806\n",
      "Test:  [[2447   31]\n",
      " [ 359   10]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and numeral\n",
      "Test:  0.02583979328165375\n",
      "Test:  [[2465   13]\n",
      " [ 364    5]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.03508771929824561\n",
      "Test:  [[2455   23]\n",
      " [ 362    7]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.03902439024390243\n",
      "Test:  [[2445   33]\n",
      " [ 361    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.030769230769230774\n",
      "Test:  [[2463   15]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.015113350125944584\n",
      "Test:  [[2453   25]\n",
      " [ 366    3]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.02583979328165375\n",
      "Test:  [[2465   13]\n",
      " [ 364    5]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.03980099502487562\n",
      "Test:  [[2453   25]\n",
      " [ 361    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.005405405405405406\n",
      "Test:  [[2478    0]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.035443037974683546\n",
      "Test:  [[2459   19]\n",
      " [ 362    7]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.04455445544554455\n",
      "Test:  [[2452   26]\n",
      " [ 360    9]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.005277044854881266\n",
      "Test:  [[2469    9]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.032\n",
      "Test:  [[2724    0]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and plot\n",
      "Test:  0.0923076923076923\n",
      "Test:  [[2723    1]\n",
      " [ 117    6]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and verbs\n",
      "Test:  0.09022556390977443\n",
      "Test:  [[2720    4]\n",
      " [ 117    6]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and nouns\n",
      "Test:  0.0923076923076923\n",
      "Test:  [[2723    1]\n",
      " [ 117    6]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and adjectives\n",
      "Test:  0.06250000000000001\n",
      "Test:  [[2723    1]\n",
      " [ 119    4]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and numeral\n",
      "Test:  0.046875\n",
      "Test:  [[2722    2]\n",
      " [ 120    3]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and plot\n",
      "Test:  0.21917808219178084\n",
      "Test:  [[2717    7]\n",
      " [ 107   16]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and verbs\n",
      "Test:  0.09929078014184398\n",
      "Test:  [[2713   11]\n",
      " [ 116    7]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and nouns\n",
      "Test:  0.273972602739726\n",
      "Test:  [[2721    3]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.2781456953642384\n",
      "Test:  [[2717    7]\n",
      " [ 102   21]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and numeral\n",
      "Test:  0.04724409448818898\n",
      "Test:  [[2723    1]\n",
      " [ 120    3]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.29333333333333333\n",
      "Test:  [[2719    5]\n",
      " [ 101   22]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.09999999999999999\n",
      "Test:  [[2714   10]\n",
      " [ 116    7]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.2620689655172414\n",
      "Test:  [[2721    3]\n",
      " [ 104   19]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.27999999999999997\n",
      "Test:  [[2718    6]\n",
      " [ 102   21]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.04724409448818898\n",
      "Test:  [[2723    1]\n",
      " [ 120    3]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.19858156028368795\n",
      "Test:  [[2720    4]\n",
      " [ 109   14]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.03174603174603175\n",
      "Test:  [[2723    1]\n",
      " [ 121    2]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.2876712328767123\n",
      "Test:  [[2722    2]\n",
      " [ 102   21]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.28187919463087246\n",
      "Test:  [[2719    5]\n",
      " [ 102   21]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.046875\n",
      "Test:  [[2722    2]\n",
      " [ 120    3]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.01658374792703151\n",
      "Test:  [[2249    8]\n",
      " [ 585    5]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2257    0]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.03566121842496285\n",
      "Test:  [[2186   71]\n",
      " [ 578   12]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.044709388971684055\n",
      "Test:  [[2191   66]\n",
      " [ 575   15]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.01983471074380165\n",
      "Test:  [[2248    9]\n",
      " [ 584    6]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and plot\n",
      "Test:  0.026016260162601626\n",
      "Test:  [[2240   17]\n",
      " [ 582    8]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and verbs\n",
      "Test:  0.038034865293185414\n",
      "Test:  [[2228   29]\n",
      " [ 578   12]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and nouns\n",
      "Test:  0.062111801242236024\n",
      "Test:  [[2223   34]\n",
      " [ 570   20]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and adjectives\n",
      "Test:  0.01636661211129296\n",
      "Test:  [[2241   16]\n",
      " [ 585    5]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and numeral\n",
      "Test:  0.03194888178913738\n",
      "Test:  [[2231   26]\n",
      " [ 580   10]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and plot\n",
      "Test:  0.06017191977077364\n",
      "Test:  [[2170   87]\n",
      " [ 569   21]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and verbs\n",
      "Test:  0.05182926829268293\n",
      "Test:  [[2208   49]\n",
      " [ 573   17]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and nouns\n",
      "Test:  0.055800293685756244\n",
      "Test:  [[2185   72]\n",
      " [ 571   19]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and adjectives\n",
      "Test:  0.10212765957446811\n",
      "Test:  [[2178   79]\n",
      " [ 554   36]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and numeral\n",
      "Test:  0.04457652303120357\n",
      "Test:  [[2189   68]\n",
      " [ 575   15]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.08055555555555556\n",
      "Test:  [[2156  101]\n",
      " [ 561   29]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.06431852986217458\n",
      "Test:  [[2215   42]\n",
      " [ 569   21]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.07492795389048992\n",
      "Test:  [[2179   78]\n",
      " [ 564   26]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.08869814020028612\n",
      "Test:  [[2179   78]\n",
      " [ 559   31]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.04457652303120357\n",
      "Test:  [[2189   68]\n",
      " [ 575   15]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.05714285714285715\n",
      "Test:  [[2167   90]\n",
      " [ 570   20]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2255    2]\n",
      " [ 590    0]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.07714285714285715\n",
      "Test:  [[2174   83]\n",
      " [ 563   27]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.09943181818181818\n",
      "Test:  [[2178   79]\n",
      " [ 555   35]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.03508771929824562\n",
      "Test:  [[2231   26]\n",
      " [ 579   11]]\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=7)\n",
    "output_knn = train_with_settings(genres, vect_strategies, feature_strategies, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_murder TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.5867082035306335\n",
      "Test:  [[1486  224]\n",
      " [ 572  565]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.41428571428571426\n",
      "Test:  [[1515  195]\n",
      " [ 789  348]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.5697612732095491\n",
      "Test:  [[1499  211]\n",
      " [ 600  537]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.47944412275622467\n",
      "Test:  [[1534  176]\n",
      " [ 723  414]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.27726432532347506\n",
      "Test:  [[1449  261]\n",
      " [ 912  225]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and plot\n",
      "Test:  0.5938954992240042\n",
      "Test:  [[1488  222]\n",
      " [ 563  574]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and verbs\n",
      "Test:  0.4444444444444444\n",
      "Test:  [[1489  221]\n",
      " [ 749  388]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and nouns\n",
      "Test:  0.6038696537678209\n",
      "Test:  [[1476  234]\n",
      " [ 544  593]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and adjectives\n",
      "Test:  0.5073115860517435\n",
      "Test:  [[1520  190]\n",
      " [ 686  451]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and numeral\n",
      "Test:  0.3223981900452489\n",
      "Test:  [[1364  346]\n",
      " [ 852  285]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and plot\n",
      "Test:  0.5585874799357945\n",
      "Test:  [[1500  210]\n",
      " [ 615  522]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and verbs\n",
      "Test:  0.3911483253588517\n",
      "Test:  [[1502  208]\n",
      " [ 810  327]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and nouns\n",
      "Test:  0.5628356605800215\n",
      "Test:  [[1509  201]\n",
      " [ 613  524]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and adjectives\n",
      "Test:  0.46386946386946387\n",
      "Test:  [[1529  181]\n",
      " [ 739  398]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and numeral\n",
      "Test:  0.2653316645807259\n",
      "Test:  [[1461  249]\n",
      " [ 925  212]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.609805924412666\n",
      "Test:  [[1486  224]\n",
      " [ 540  597]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.3937387116195063\n",
      "Test:  [[1513  197]\n",
      " [ 810  327]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.6201705970898144\n",
      "Test:  [[1472  238]\n",
      " [ 519  618]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.5185595567867036\n",
      "Test:  [[1510  200]\n",
      " [ 669  468]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.23939202026599113\n",
      "Test:  [[1457  253]\n",
      " [ 948  189]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.5933609958506224\n",
      "Test:  [[1491  219]\n",
      " [ 565  572]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.42964678633468434\n",
      "Test:  [[1491  219]\n",
      " [ 766  371]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.5846477392218717\n",
      "Test:  [[1501  209]\n",
      " [ 581  556]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.48993674525589415\n",
      "Test:  [[1534  176]\n",
      " [ 711  426]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.22597402597402597\n",
      "Test:  [[1481  229]\n",
      " [ 963  174]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.04195804195804196\n",
      "Test:  [[2287   15]\n",
      " [ 533   12]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.051993067590987874\n",
      "Test:  [[2285   17]\n",
      " [ 530   15]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.045454545454545456\n",
      "Test:  [[2288   14]\n",
      " [ 532   13]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.04203152364273205\n",
      "Test:  [[2288   14]\n",
      " [ 533   12]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.07350689127105665\n",
      "Test:  [[2218   84]\n",
      " [ 521   24]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and plot\n",
      "Test:  0.03859649122807018\n",
      "Test:  [[2288   14]\n",
      " [ 534   11]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and verbs\n",
      "Test:  0.06206896551724138\n",
      "Test:  [[2285   17]\n",
      " [ 527   18]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and nouns\n",
      "Test:  0.041811846689895474\n",
      "Test:  [[2285   17]\n",
      " [ 533   12]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and adjectives\n",
      "Test:  0.04878048780487806\n",
      "Test:  [[2287   15]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and numeral\n",
      "Test:  0.09024745269286755\n",
      "Test:  [[2191  111]\n",
      " [ 514   31]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and plot\n",
      "Test:  0.04869565217391305\n",
      "Test:  [[2286   16]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and verbs\n",
      "Test:  0.06551724137931036\n",
      "Test:  [[2286   16]\n",
      " [ 526   19]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and nouns\n",
      "Test:  0.04861111111111111\n",
      "Test:  [[2285   17]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and adjectives\n",
      "Test:  0.04203152364273205\n",
      "Test:  [[2288   14]\n",
      " [ 533   12]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and numeral\n",
      "Test:  0.07120743034055727\n",
      "Test:  [[2224   78]\n",
      " [ 522   23]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.06551724137931036\n",
      "Test:  [[2286   16]\n",
      " [ 526   19]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.04844290657439446\n",
      "Test:  [[2283   19]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.062176165803108814\n",
      "Test:  [[2286   16]\n",
      " [ 527   18]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.03859649122807018\n",
      "Test:  [[2288   14]\n",
      " [ 534   11]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.07012195121951219\n",
      "Test:  [[2214   88]\n",
      " [ 522   23]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.06228373702422146\n",
      "Test:  [[2287   15]\n",
      " [ 527   18]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.042105263157894736\n",
      "Test:  [[2289   13]\n",
      " [ 533   12]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.05217391304347826\n",
      "Test:  [[2287   15]\n",
      " [ 530   15]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.03852889667250438\n",
      "Test:  [[2287   15]\n",
      " [ 534   11]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.051446945337620585\n",
      "Test:  [[2241   61]\n",
      " [ 529   16]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.03133159268929504\n",
      "Test:  [[2470    8]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.010554089709762533\n",
      "Test:  [[2470    8]\n",
      " [ 367    2]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.005277044854881266\n",
      "Test:  [[2469    9]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.005305039787798409\n",
      "Test:  [[2471    7]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.004889975550122249\n",
      "Test:  [[2439   39]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and plot\n",
      "Test:  0.03108808290155441\n",
      "Test:  [[2467   11]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and nouns\n",
      "Test:  0.04145077720207253\n",
      "Test:  [[2469    9]\n",
      " [ 361    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and adjectives\n",
      "Test:  0.02099737532808399\n",
      "Test:  [[2470    8]\n",
      " [ 365    4]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and numeral\n",
      "Test:  0.014634146341463415\n",
      "Test:  [[2440   38]\n",
      " [ 366    3]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and plot\n",
      "Test:  0.005305039787798409\n",
      "Test:  [[2471    7]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and numeral\n",
      "Test:  0.01015228426395939\n",
      "Test:  [[2455   23]\n",
      " [ 367    2]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.0\n",
      "Test:  [[2470    8]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2470    8]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.01015228426395939\n",
      "Test:  [[2455   23]\n",
      " [ 367    2]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.0\n",
      "Test:  [[2471    7]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.00505050505050505\n",
      "Test:  [[2452   26]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.2553191489361702\n",
      "Test:  [[2724    0]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.20689655172413793\n",
      "Test:  [[2717    7]\n",
      " [ 108   15]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and plot\n",
      "Test:  0.2777777777777778\n",
      "Test:  [[2723    1]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and verbs\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and nouns\n",
      "Test:  0.3466666666666667\n",
      "Test:  [[2723    1]\n",
      " [  97   26]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and adjectives\n",
      "Test:  0.2777777777777778\n",
      "Test:  [[2723    1]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and numeral\n",
      "Test:  0.20547945205479454\n",
      "Test:  [[2716    8]\n",
      " [ 108   15]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and plot\n",
      "Test:  0.2535211267605633\n",
      "Test:  [[2723    1]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and verbs\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and nouns\n",
      "Test:  0.2535211267605633\n",
      "Test:  [[2723    1]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.2553191489361702\n",
      "Test:  [[2724    0]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and numeral\n",
      "Test:  0.20833333333333334\n",
      "Test:  [[2718    6]\n",
      " [ 108   15]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.26573426573426573\n",
      "Test:  [[2723    1]\n",
      " [ 104   19]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.27972027972027974\n",
      "Test:  [[2724    0]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.2535211267605633\n",
      "Test:  [[2723    1]\n",
      " [ 105   18]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.20833333333333334\n",
      "Test:  [[2718    6]\n",
      " [ 108   15]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.2777777777777778\n",
      "Test:  [[2723    1]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.26573426573426573\n",
      "Test:  [[2723    1]\n",
      " [ 104   19]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.24285714285714285\n",
      "Test:  [[2724    0]\n",
      " [ 106   17]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.22068965517241382\n",
      "Test:  [[2718    6]\n",
      " [ 107   16]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.10429447852760736\n",
      "Test:  [[2229   28]\n",
      " [ 556   34]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.029459901800327332\n",
      "Test:  [[2245   12]\n",
      " [ 581    9]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.0576\n",
      "Test:  [[2240   17]\n",
      " [ 572   18]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.03559870550161813\n",
      "Test:  [[2240   17]\n",
      " [ 579   11]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.06734992679355785\n",
      "Test:  [[2187   70]\n",
      " [ 567   23]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and plot\n",
      "Test:  0.06299212598425197\n",
      "Test:  [[2232   25]\n",
      " [ 570   20]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and verbs\n",
      "Test:  0.03273322422258592\n",
      "Test:  [[2246   11]\n",
      " [ 580   10]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and nouns\n",
      "Test:  0.0631911532385466\n",
      "Test:  [[2234   23]\n",
      " [ 570   20]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and adjectives\n",
      "Test:  0.035541195476575124\n",
      "Test:  [[2239   18]\n",
      " [ 579   11]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and numeral\n",
      "Test:  0.09269662921348315\n",
      "Test:  [[2168   89]\n",
      " [ 557   33]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and plot\n",
      "Test:  0.04200323101777059\n",
      "Test:  [[2241   16]\n",
      " [ 577   13]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and verbs\n",
      "Test:  0.022988505747126436\n",
      "Test:  [[2245   12]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and nouns\n",
      "Test:  0.02622950819672131\n",
      "Test:  [[2245   12]\n",
      " [ 582    8]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and adjectives\n",
      "Test:  0.023064250411861616\n",
      "Test:  [[2247   10]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and numeral\n",
      "Test:  0.04504504504504506\n",
      "Test:  [[2196   61]\n",
      " [ 575   15]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.048465266558966075\n",
      "Test:  [[2243   14]\n",
      " [ 575   15]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.023064250411861616\n",
      "Test:  [[2247   10]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.03257328990228013\n",
      "Test:  [[2243   14]\n",
      " [ 580   10]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.023064250411861616\n",
      "Test:  [[2247   10]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.04504504504504506\n",
      "Test:  [[2196   61]\n",
      " [ 575   15]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.04560260586319219\n",
      "Test:  [[2247   10]\n",
      " [ 576   14]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.023026315789473683\n",
      "Test:  [[2246   11]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.032520325203252036\n",
      "Test:  [[2242   15]\n",
      " [ 580   10]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.023064250411861616\n",
      "Test:  [[2247   10]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.037617554858934164\n",
      "Test:  [[2221   36]\n",
      " [ 578   12]]\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "output_rfc = train_with_settings(genres, vect_strategies, feature_strategies, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_murder TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.6774641369736233\n",
      "Test:  [[1418  292]\n",
      " [ 405  732]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.5347804637395165\n",
      "Test:  [[1362  348]\n",
      " [ 595  542]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.6707089552238805\n",
      "Test:  [[1422  288]\n",
      " [ 418  719]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.5294748124330116\n",
      "Test:  [[1475  235]\n",
      " [ 643  494]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.1081081081081081\n",
      "Test:  [[1657   53]\n",
      " [1069   68]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and plot\n",
      "Test:  0.6710097719869706\n",
      "Test:  [[1419  291]\n",
      " [ 416  721]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and verbs\n",
      "Test:  0.5377215189873419\n",
      "Test:  [[1403  307]\n",
      " [ 606  531]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and nouns\n",
      "Test:  0.6713814238566714\n",
      "Test:  [[1438  272]\n",
      " [ 425  712]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and adjectives\n",
      "Test:  0.5345474022495983\n",
      "Test:  [[1479  231]\n",
      " [ 638  499]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR cv and numeral\n",
      "Test:  0.0856911883589329\n",
      "Test:  [[1663   47]\n",
      " [1084   53]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and plot\n",
      "Test:  0.6845698680018207\n",
      "Test:  [[1402  308]\n",
      " [ 385  752]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and verbs\n",
      "Test:  0.5485272815065185\n",
      "Test:  [[1344  366]\n",
      " [ 569  568]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and nouns\n",
      "Test:  0.669467787114846\n",
      "Test:  [[1422  288]\n",
      " [ 420  717]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and adjectives\n",
      "Test:  0.5430672268907564\n",
      "Test:  [[1460  250]\n",
      " [ 620  517]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf and numeral\n",
      "Test:  0.08856682769726248\n",
      "Test:  [[1660   50]\n",
      " [1082   55]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.6829493087557603\n",
      "Test:  [[1418  292]\n",
      " [ 396  741]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.5503614457831326\n",
      "Test:  [[1343  367]\n",
      " [ 566  571]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.6747550163322446\n",
      "Test:  [[1427  283]\n",
      " [ 414  723]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.5324881141045958\n",
      "Test:  [[1458  252]\n",
      " [ 633  504]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.08576051779935276\n",
      "Test:  [[1664   46]\n",
      " [1084   53]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.6878980891719746\n",
      "Test:  [[1405  305]\n",
      " [ 381  756]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.5484656600097418\n",
      "Test:  [[1357  353]\n",
      " [ 574  563]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.6735074626865671\n",
      "Test:  [[1425  285]\n",
      " [ 415  722]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.5385018334206391\n",
      "Test:  [[1452  258]\n",
      " [ 623  514]]\n",
      "===========================================\n",
      "is_murder TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.11682242990654204\n",
      "Test:  [[1638   72]\n",
      " [1062   75]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.1848998459167951\n",
      "Test:  [[2258   44]\n",
      " [ 485   60]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.08547008547008549\n",
      "Test:  [[2287   15]\n",
      " [ 520   25]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.13592233009708737\n",
      "Test:  [[2271   31]\n",
      " [ 503   42]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.04513888888888889\n",
      "Test:  [[2284   18]\n",
      " [ 532   13]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.03180212014134276\n",
      "Test:  [[2290   12]\n",
      " [ 536    9]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and plot\n",
      "Test:  0.2089093701996928\n",
      "Test:  [[2264   38]\n",
      " [ 477   68]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and verbs\n",
      "Test:  0.08873720136518772\n",
      "Test:  [[2287   15]\n",
      " [ 519   26]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and nouns\n",
      "Test:  0.16113744075829384\n",
      "Test:  [[2265   37]\n",
      " [ 494   51]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and adjectives\n",
      "Test:  0.05882352941176471\n",
      "Test:  [[2286   16]\n",
      " [ 528   17]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR cv and numeral\n",
      "Test:  0.0108499095840868\n",
      "Test:  [[2297    5]\n",
      " [ 542    3]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and plot\n",
      "Test:  0.20974889217134413\n",
      "Test:  [[2241   61]\n",
      " [ 474   71]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and verbs\n",
      "Test:  0.08798646362098139\n",
      "Test:  [[2282   20]\n",
      " [ 519   26]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and nouns\n",
      "Test:  0.15360501567398122\n",
      "Test:  [[2258   44]\n",
      " [ 496   49]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and adjectives\n",
      "Test:  0.06101694915254238\n",
      "Test:  [[2275   27]\n",
      " [ 527   18]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf and numeral\n",
      "Test:  0.020833333333333332\n",
      "Test:  [[2277   25]\n",
      " [ 539    6]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.20926756352765322\n",
      "Test:  [[2248   54]\n",
      " [ 475   70]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.08985024958402664\n",
      "Test:  [[2273   29]\n",
      " [ 518   27]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.17099236641221374\n",
      "Test:  [[2248   54]\n",
      " [ 489   56]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.05811965811965812\n",
      "Test:  [[2279   23]\n",
      " [ 528   17]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.017452006980802792\n",
      "Test:  [[2279   23]\n",
      " [ 540    5]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.20241691842900303\n",
      "Test:  [[2252   50]\n",
      " [ 478   67]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.10684474123539232\n",
      "Test:  [[2280   22]\n",
      " [ 513   32]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.1894409937888199\n",
      "Test:  [[2264   38]\n",
      " [ 484   61]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.04835924006908463\n",
      "Test:  [[2282   20]\n",
      " [ 531   14]]\n",
      "===========================================\n",
      "is_romantic TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.0035650623885918006\n",
      "Test:  [[2287   15]\n",
      " [ 544    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.04639175257731959\n",
      "Test:  [[2468   10]\n",
      " [ 360    9]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.005333333333333334\n",
      "Test:  [[2473    5]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.04060913705583756\n",
      "Test:  [[2461   17]\n",
      " [ 361    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.026525198938992047\n",
      "Test:  [[2475    3]\n",
      " [ 364    5]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2476    2]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and plot\n",
      "Test:  0.055837563451776644\n",
      "Test:  [[2464   14]\n",
      " [ 358   11]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and verbs\n",
      "Test:  0.015873015873015876\n",
      "Test:  [[2472    6]\n",
      " [ 366    3]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and nouns\n",
      "Test:  0.06532663316582914\n",
      "Test:  [[2462   16]\n",
      " [ 356   13]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and adjectives\n",
      "Test:  0.03655352480417755\n",
      "Test:  [[2471    7]\n",
      " [ 362    7]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR cv and numeral\n",
      "Test:  0.010610079575596818\n",
      "Test:  [[2472    6]\n",
      " [ 367    2]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and plot\n",
      "Test:  0.040920716112531966\n",
      "Test:  [[2464   14]\n",
      " [ 361    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and verbs\n",
      "Test:  0.005291005291005292\n",
      "Test:  [[2470    8]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and nouns\n",
      "Test:  0.021052631578947368\n",
      "Test:  [[2471    7]\n",
      " [ 365    4]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.0213903743315508\n",
      "Test:  [[2477    1]\n",
      " [ 365    4]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf and numeral\n",
      "Test:  0.005390835579514824\n",
      "Test:  [[2477    1]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.05025125628140704\n",
      "Test:  [[2459   19]\n",
      " [ 359   10]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.005333333333333334\n",
      "Test:  [[2473    5]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.020618556701030927\n",
      "Test:  [[2463   15]\n",
      " [ 365    4]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.03149606299212599\n",
      "Test:  [[2472    6]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.0\n",
      "Test:  [[2477    1]\n",
      " [ 369    0]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.041343669250646\n",
      "Test:  [[2468   10]\n",
      " [ 361    8]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.010666666666666668\n",
      "Test:  [[2474    4]\n",
      " [ 367    2]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.0310077519379845\n",
      "Test:  [[2466   12]\n",
      " [ 363    6]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.0106951871657754\n",
      "Test:  [[2475    3]\n",
      " [ 367    2]]\n",
      "===========================================\n",
      "is_comedy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.005376344086021505\n",
      "Test:  [[2476    2]\n",
      " [ 368    1]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.49438202247191015\n",
      "Test:  [[2713   11]\n",
      " [  79   44]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.28571428571428575\n",
      "Test:  [[2715    9]\n",
      " [ 101   22]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.4235294117647058\n",
      "Test:  [[2713   11]\n",
      " [  87   36]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.41379310344827586\n",
      "Test:  [[2709   15]\n",
      " [  87   36]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.06015037593984963\n",
      "Test:  [[2718    6]\n",
      " [ 119    4]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and plot\n",
      "Test:  0.49756097560975604\n",
      "Test:  [[2693   31]\n",
      " [  72   51]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and verbs\n",
      "Test:  0.2631578947368421\n",
      "Test:  [[2715    9]\n",
      " [ 103   20]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and nouns\n",
      "Test:  0.42162162162162165\n",
      "Test:  [[2701   23]\n",
      " [  84   39]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and adjectives\n",
      "Test:  0.40860215053763443\n",
      "Test:  [[2699   25]\n",
      " [  85   38]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR cv and numeral\n",
      "Test:  0.05925925925925926\n",
      "Test:  [[2716    8]\n",
      " [ 119    4]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and plot\n",
      "Test:  0.44554455445544555\n",
      "Test:  [[2690   34]\n",
      " [  78   45]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and verbs\n",
      "Test:  0.19736842105263158\n",
      "Test:  [[2710   14]\n",
      " [ 108   15]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and nouns\n",
      "Test:  0.39999999999999997\n",
      "Test:  [[2695   29]\n",
      " [  85   38]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and adjectives\n",
      "Test:  0.328042328042328\n",
      "Test:  [[2689   35]\n",
      " [  92   31]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf and numeral\n",
      "Test:  0.08695652173913045\n",
      "Test:  [[2715    9]\n",
      " [ 117    6]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.41269841269841273\n",
      "Test:  [[2697   27]\n",
      " [  84   39]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.18543046357615894\n",
      "Test:  [[2710   14]\n",
      " [ 109   14]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.3877551020408163\n",
      "Test:  [[2689   35]\n",
      " [  85   38]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.36363636363636365\n",
      "Test:  [[2694   30]\n",
      " [  89   34]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.072992700729927\n",
      "Test:  [[2715    9]\n",
      " [ 118    5]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.4321608040201005\n",
      "Test:  [[2691   33]\n",
      " [  80   43]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.22891566265060243\n",
      "Test:  [[2700   24]\n",
      " [ 104   19]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.3516483516483517\n",
      "Test:  [[2697   27]\n",
      " [  91   32]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.37113402061855666\n",
      "Test:  [[2689   35]\n",
      " [  87   36]]\n",
      "===========================================\n",
      "is_fantasy TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.10606060606060606\n",
      "Test:  [[2722    2]\n",
      " [ 116    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and plot\n",
      "Test:  0.2351313969571231\n",
      "Test:  [[2209   48]\n",
      " [ 505   85]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and verbs\n",
      "Test:  0.036065573770491806\n",
      "Test:  [[2248    9]\n",
      " [ 579   11]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and nouns\n",
      "Test:  0.2034383954154728\n",
      "Test:  [[2220   37]\n",
      " [ 519   71]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and adjectives\n",
      "Test:  0.044871794871794865\n",
      "Test:  [[2237   20]\n",
      " [ 576   14]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv_ngram_binary and numeral\n",
      "Test:  0.01951219512195122\n",
      "Test:  [[2238   19]\n",
      " [ 584    6]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and plot\n",
      "Test:  0.24725274725274726\n",
      "Test:  [[2209   48]\n",
      " [ 500   90]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and verbs\n",
      "Test:  0.05483870967741935\n",
      "Test:  [[2244   13]\n",
      " [ 573   17]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and nouns\n",
      "Test:  0.1974612129760226\n",
      "Test:  [[2208   49]\n",
      " [ 520   70]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and adjectives\n",
      "Test:  0.022801302931596094\n",
      "Test:  [[2240   17]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR cv and numeral\n",
      "Test:  0.026143790849673203\n",
      "Test:  [[2243   14]\n",
      " [ 582    8]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and plot\n",
      "Test:  0.29100529100529104\n",
      "Test:  [[2201   56]\n",
      " [ 480  110]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and verbs\n",
      "Test:  0.026446280991735537\n",
      "Test:  [[2250    7]\n",
      " [ 582    8]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and nouns\n",
      "Test:  0.20419580419580421\n",
      "Test:  [[2205   52]\n",
      " [ 517   73]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and adjectives\n",
      "Test:  0.04567699836867863\n",
      "Test:  [[2248    9]\n",
      " [ 576   14]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf and numeral\n",
      "Test:  0.03565640194489465\n",
      "Test:  [[2241   16]\n",
      " [ 579   11]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and plot\n",
      "Test:  0.25771812080536916\n",
      "Test:  [[2198   59]\n",
      " [ 494   96]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and verbs\n",
      "Test:  0.023064250411861616\n",
      "Test:  [[2247   10]\n",
      " [ 583    7]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and nouns\n",
      "Test:  0.217877094972067\n",
      "Test:  [[2209   48]\n",
      " [ 512   78]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and adjectives\n",
      "Test:  0.04516129032258065\n",
      "Test:  [[2241   16]\n",
      " [ 576   14]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_maxdf and numeral\n",
      "Test:  0.038834951456310676\n",
      "Test:  [[2241   16]\n",
      " [ 578   12]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and plot\n",
      "Test:  0.2679296346414073\n",
      "Test:  [[2207   50]\n",
      " [ 491   99]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and verbs\n",
      "Test:  0.016611295681063124\n",
      "Test:  [[2250    7]\n",
      " [ 585    5]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and nouns\n",
      "Test:  0.21468926553672316\n",
      "Test:  [[2215   42]\n",
      " [ 514   76]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and adjectives\n",
      "Test:  0.0361247947454844\n",
      "Test:  [[2249    8]\n",
      " [ 579   11]]\n",
      "===========================================\n",
      "is_flashback TRAIN FOR tfidf_bigr and numeral\n",
      "Test:  0.013179571663920921\n",
      "Test:  [[2244   13]\n",
      " [ 586    4]]\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "output_gbc = train_with_settings(genres, vect_strategies, feature_strategies, clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_clf(dict_of_res):\n",
    "    all_ = [v for k, v in dict_of_res.items() if genre in k]\n",
    "    all_metrics_test = [x['f1_test'] for x in all_]\n",
    "    best_for_genre = max(all_metrics_test)\n",
    "    index_mnb = all_metrics_test.index(best_for_genre)\n",
    "    return all_[index_mnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test scores for genre is_murder: \n",
      "Decision Tree: 0.6113342257920571\n",
      "Multinomial NB: 0.6597582037996547\n",
      "KNN: 0.49605411499436314\n",
      "Random Forest: 0.6201705970898144\n",
      "Gradient Boosting: 0.6878980891719746\n",
      "Best test scores for genre is_romantic: \n",
      "Decision Tree: 0.3374880153403644\n",
      "Multinomial NB: 0.46972176759410805\n",
      "KNN: 0.14222222222222222\n",
      "Random Forest: 0.09024745269286755\n",
      "Gradient Boosting: 0.20974889217134413\n",
      "Best test scores for genre is_comedy: \n",
      "Decision Tree: 0.18524332810047095\n",
      "Multinomial NB: 0.2874806800618238\n",
      "KNN: 0.05025125628140704\n",
      "Random Forest: 0.04145077720207253\n",
      "Gradient Boosting: 0.06532663316582914\n",
      "Best test scores for genre is_fantasy: \n",
      "Decision Tree: 0.4716981132075472\n",
      "Multinomial NB: 0.5303030303030303\n",
      "KNN: 0.29333333333333333\n",
      "Random Forest: 0.3466666666666667\n",
      "Gradient Boosting: 0.49756097560975604\n",
      "Best test scores for genre is_flashback: \n",
      "Decision Tree: 0.31205673758865243\n",
      "Multinomial NB: 0.3028229255774166\n",
      "KNN: 0.10212765957446811\n",
      "Random Forest: 0.10429447852760736\n",
      "Gradient Boosting: 0.29100529100529104\n"
     ]
    }
   ],
   "source": [
    "best_clfs = {}\n",
    "for genre in genres:\n",
    "    best_dec_trees = select_best_clf(output_dec_trees)\n",
    "    best_mnb = select_best_clf(output_mnb)\n",
    "    best_knn = select_best_clf(output_knn)\n",
    "    best_rfc = select_best_clf(output_rfc)\n",
    "    best_gbc = select_best_clf(output_gbc)\n",
    "    \n",
    "    print(f'Best test scores for genre {genre}: ')\n",
    "    print(f'Decision Tree: {best_dec_trees[\"f1_test\"]}')\n",
    "    print(f'Multinomial NB: {best_mnb[\"f1_test\"]}')\n",
    "    print(f'KNN: {best_knn[\"f1_test\"]}')\n",
    "    print(f'Random Forest: {best_rfc[\"f1_test\"]}')\n",
    "    print(f'Gradient Boosting: {best_gbc[\"f1_test\"]}')\n",
    "    \n",
    "    all_ = [best_dec_trees, best_mnb, best_knn, best_rfc, best_gbc]\n",
    "    all_m = [x['f1_test'] for x in all_]\n",
    "    best_for_genre = max(all_m)\n",
    "    index_mnb = all_m.index(best_for_genre)\n",
    "    best_clfs[genre] = all_[index_mnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test_overall = np.concatenate([\n",
    "    best_clfs['is_murder']['y_val_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_romantic']['y_val_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_comedy']['y_val_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_fantasy']['y_val_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_flashback']['y_val_pred'].reshape(-1, 1)\n",
    "], axis = 1)\n",
    "\n",
    "y_pred_test_overall = np.concatenate([\n",
    "    best_clfs['is_murder']['y_test_all_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_romantic']['y_test_all_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_comedy']['y_test_all_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_fantasy']['y_test_all_pred'].reshape(-1, 1),\n",
    "    best_clfs['is_flashback']['y_test_all_pred'].reshape(-1, 1)\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5339 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4\n",
       "0     0  1  0  0  0\n",
       "1     1  0  1  0  0\n",
       "2     0  1  1  0  0\n",
       "3     1  0  0  0  0\n",
       "4     0  1  1  0  1\n",
       "...  .. .. .. .. ..\n",
       "5334  1  0  0  0  0\n",
       "5335  0  1  0  0  0\n",
       "5336  1  0  1  0  0\n",
       "5337  1  0  0  0  0\n",
       "5338  0  1  0  0  0\n",
       "\n",
       "[5339 rows x 5 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_df = pd.DataFrame(y_pred_test_overall)\n",
    "ans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['romantic',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'romantic, comedy, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'murder, romantic',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'comedy',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'comedy, flashback',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder, comedy, flashback',\n",
       " 'comedy',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " '',\n",
       " 'fantasy, flashback',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " '',\n",
       " 'fantasy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'murder, flashback',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'romantic, comedy',\n",
       " 'comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'romantic, flashback',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder, flashback',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic, flashback',\n",
       " 'murder, comedy',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'fantasy, flashback',\n",
       " '',\n",
       " 'fantasy',\n",
       " '',\n",
       " 'flashback',\n",
       " '',\n",
       " '',\n",
       " 'murder, romantic',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " 'comedy',\n",
       " 'romantic, fantasy',\n",
       " 'murder, fantasy',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'comedy',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'romantic, fantasy',\n",
       " 'murder, comedy',\n",
       " 'murder, flashback',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, romantic',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder, romantic, comedy',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder, romantic, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder, romantic',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'fantasy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'romantic, fantasy',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'flashback',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'romantic, comedy, flashback',\n",
       " 'comedy',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " 'romantic, fantasy',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic, fantasy, flashback',\n",
       " 'romantic, comedy, flashback',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " 'murder, comedy, flashback',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " '',\n",
       " 'comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder, romantic',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'murder, romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'flashback',\n",
       " 'fantasy, flashback',\n",
       " 'romantic, flashback',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'fantasy',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder, romantic',\n",
       " '',\n",
       " 'comedy',\n",
       " '',\n",
       " 'fantasy',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " 'comedy, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'romantic, flashback',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder, romantic',\n",
       " 'comedy',\n",
       " '',\n",
       " 'fantasy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'comedy, fantasy',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic, fantasy',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'murder, romantic',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'comedy, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, romantic, flashback',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic, fantasy',\n",
       " 'flashback',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'murder, romantic, comedy',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'romantic, flashback',\n",
       " 'fantasy, flashback',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder, romantic',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'murder',\n",
       " 'murder, romantic',\n",
       " 'romantic, comedy',\n",
       " 'comedy',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'fantasy',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " '',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'fantasy',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'murder, romantic',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'romantic, fantasy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'romantic, fantasy',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " 'romantic, flashback',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " 'murder, flashback',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " '',\n",
       " 'fantasy',\n",
       " 'murder, comedy',\n",
       " 'comedy',\n",
       " 'fantasy',\n",
       " 'murder, romantic, comedy, flashback',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'flashback',\n",
       " 'murder, comedy, flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy, flashback',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'romantic, flashback',\n",
       " 'murder, comedy',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'flashback',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'flashback',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder, flashback',\n",
       " 'murder, comedy',\n",
       " 'comedy',\n",
       " 'romantic, comedy, flashback',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " 'romantic',\n",
       " 'comedy, fantasy',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'romantic, comedy, flashback',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " 'fantasy, flashback',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy, flashback',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder, fantasy, flashback',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder, flashback',\n",
       " 'comedy',\n",
       " 'fantasy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'fantasy',\n",
       " 'murder, comedy',\n",
       " 'murder, flashback',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'fantasy',\n",
       " 'flashback',\n",
       " 'murder',\n",
       " 'fantasy',\n",
       " 'murder',\n",
       " 'flashback',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic, comedy, flashback',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'comedy',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'murder, comedy, flashback',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " 'murder, romantic',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic, fantasy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'flashback',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, romantic',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder, comedy, flashback',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'romantic, comedy, flashback',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " 'fantasy',\n",
       " 'fantasy',\n",
       " 'romantic',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'romantic, flashback',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'flashback',\n",
       " 'flashback',\n",
       " 'fantasy',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'comedy, flashback',\n",
       " 'murder, comedy',\n",
       " 'fantasy, flashback',\n",
       " '',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'fantasy',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder',\n",
       " 'comedy, flashback',\n",
       " 'flashback',\n",
       " 'comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic, comedy, flashback',\n",
       " 'romantic, comedy',\n",
       " 'comedy, flashback',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, flashback',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder, comedy',\n",
       " 'flashback',\n",
       " 'flashback',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, fantasy, flashback',\n",
       " 'murder',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'romantic, flashback',\n",
       " 'comedy',\n",
       " '',\n",
       " '',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " 'flashback',\n",
       " 'romantic, flashback',\n",
       " '',\n",
       " 'fantasy',\n",
       " 'murder, flashback',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'romantic',\n",
       " 'murder, flashback',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder, romantic',\n",
       " '',\n",
       " 'murder, flashback',\n",
       " 'murder, flashback',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'murder, flashback',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder, comedy, flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " 'comedy, flashback',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder, comedy',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic, flashback',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder, comedy',\n",
       " 'murder',\n",
       " 'romantic, comedy, flashback',\n",
       " 'murder, flashback',\n",
       " 'romantic, comedy',\n",
       " 'romantic',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " '',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'comedy, flashback',\n",
       " 'romantic, comedy',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder, comedy, flashback',\n",
       " '',\n",
       " '',\n",
       " 'comedy, fantasy',\n",
       " 'murder',\n",
       " 'comedy',\n",
       " 'murder',\n",
       " 'murder, romantic',\n",
       " 'murder, comedy',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " 'fantasy',\n",
       " 'murder, flashback',\n",
       " 'romantic',\n",
       " 'romantic',\n",
       " '',\n",
       " 'murder',\n",
       " '',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " 'murder',\n",
       " '',\n",
       " 'comedy',\n",
       " 'flashback',\n",
       " '',\n",
       " 'romantic, comedy',\n",
       " 'murder',\n",
       " 'murder, comedy, flashback',\n",
       " '',\n",
       " 'fantasy',\n",
       " '',\n",
       " ...]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_list = [\"murder\", \"romantic\", \"comedy\", \"fantasy\", \"flashback\"]\n",
    "temp_arr = []\n",
    "\n",
    "for i in y_pred_test_overall:\n",
    "    temp_s = []\n",
    "    for j in range(5):\n",
    "        if i[j] == 1:\n",
    "            temp_s.append(tags_list[j])\n",
    "    temp_arr.append(', '.join(temp_s))\n",
    "\n",
    "\n",
    "temp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0033045</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0086250</td>\n",
       "      <td>murder, comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1315981</td>\n",
       "      <td>romantic, comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt1937113</td>\n",
       "      <td>murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt1619029</td>\n",
       "      <td>romantic, comedy, flashback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>tt1869716</td>\n",
       "      <td>murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>tt0025601</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>tt0219952</td>\n",
       "      <td>murder, comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>tt0039464</td>\n",
       "      <td>murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>tt0235166</td>\n",
       "      <td>romantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5339 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         tags\n",
       "0     tt0033045                     romantic\n",
       "1     tt0086250               murder, comedy\n",
       "2     tt1315981             romantic, comedy\n",
       "3     tt1937113                       murder\n",
       "4     tt1619029  romantic, comedy, flashback\n",
       "...         ...                          ...\n",
       "5334  tt1869716                       murder\n",
       "5335  tt0025601                     romantic\n",
       "5336  tt0219952               murder, comedy\n",
       "5337  tt0039464                       murder\n",
       "5338  tt0235166                     romantic\n",
       "\n",
       "[5339 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = pd.DataFrame()\n",
    "answer['id'] = test_id\n",
    "\n",
    "answer['tags'] = pd.DataFrame(temp_arr)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('lab_1_Filistovich.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
